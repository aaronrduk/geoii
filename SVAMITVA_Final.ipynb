{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85a937d7",
   "metadata": {},
   "source": [
    "# SVAMITVA Feature Extraction \u2014 DGX A100 Training\n",
    "\n",
    "**Workflow:** Train one MAP at a time. After each MAP, inspect the metrics/checkpoint, then run the next MAP's cell.\n",
    "\n",
    "```\n",
    "workspace/\n",
    "\u251c\u2500\u2500 DATA/\n",
    "\u2502   \u251c\u2500\u2500 MAP1/  \u2190 tif + shapefiles\n",
    "\u2502   \u251c\u2500\u2500 MAP2/\n",
    "\u2502   \u251c\u2500\u2500 MAP3/\n",
    "\u2502   \u251c\u2500\u2500 MAP4/\n",
    "\u2502   \u2514\u2500\u2500 MAP5/\n",
    "\u2514\u2500\u2500 svamitva_model/\n",
    "    \u251c\u2500\u2500 SVAMITVA_Final.ipynb\n",
    "    \u2514\u2500\u2500 checkpoints/\n",
    "        \u251c\u2500\u2500 MAP1_best.pt      \u2190 saved after MAP1 training\n",
    "        \u251c\u2500\u2500 MAP2_best.pt      \u2190 starts from MAP1 weights\n",
    "        \u251c\u2500\u2500 MAP3_best.pt      \u2190 starts from MAP2 weights\n",
    "        \u251c\u2500\u2500 MAP4_best.pt\n",
    "        \u2514\u2500\u2500 MAP5_best.pt      \u2190 final universal model\n",
    "```\n",
    "\n",
    "**How to use:**\n",
    "1. Run **Setup** (Cell 1) once\n",
    "2. Run **MAP1 Training** (Cell 2) \u2192 inspect output \u2192 run **MAP1 Analysis** (Cell 3)\n",
    "3. Run **MAP2 Training** (Cell 4), and so on\n",
    "4. The last MAP's checkpoint is the **universal model** trained on all areas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e20c8f8",
   "metadata": {},
   "source": [
    "---\n",
    "## CELL 1 \u2014 Setup (run once)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac78d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, time\nos.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from pathlib import Path\n",
    "from torch.amp import GradScaler, autocast\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# \u2500\u2500 Paths \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
    "NOTEBOOK_DIR = Path.cwd()                     # .../svamitva_model\n",
    "DATA_DIR     = Path(\"/jupyter/sods.user04/DATA\")  # absolute path on DGX\n",
    "CKPT_DIR     = NOTEBOOK_DIR / \"checkpoints\"\n",
    "CKPT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "(NOTEBOOK_DIR / \"logs\").mkdir(exist_ok=True)\n",
    "\n",
    "if str(NOTEBOOK_DIR) not in sys.path:\n",
    "    sys.path.insert(0, str(NOTEBOOK_DIR))\n",
    "\n",
    "# \u2500\u2500 GPU info \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Notebook dir : {NOTEBOOK_DIR}\")\n",
    "print(f\"DATA dir     : {DATA_DIR}  (exists={DATA_DIR.exists()})\")\n",
    "print(f\"Checkpoints  : {CKPT_DIR}\")\n",
    "print(f\"Device       : {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        g = torch.cuda.get_device_properties(i)\n",
    "        print(f\"  GPU {i}: {g.name}  ({g.total_memory/1e9:.1f} GB)\")\n",
    "\n",
    "# \u2500\u2500 Dataset validation \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
    "SHP_PATTERNS = [\n",
    "    (\"Build_up.shp\",          \"building\"),\n",
    "    (\"Road.shp\",              \"road\"),\n",
    "    (\"Road_centre_line.shp\",  \"road_centerline\"),\n",
    "    (\"Waterbody_1.shp\",       \"waterbody\"),\n",
    "    (\"Waterbody_line_1.shp\",  \"waterbody_line\"),\n",
    "    (\"Waterbody_point_1.shp\", \"waterbody_point\"),\n",
    "    (\"Utility_1.shp\",         \"utility_line\"),\n",
    "    (\"Utility_poly_1.shp\",    \"utility_poly\"),\n",
    "    # bridge and railway not present in current dataset\n",
    "]\n",
    "\n",
    "assert DATA_DIR.exists(), f\"DATA not found: {DATA_DIR}\"\n",
    "map_dirs = sorted([d for d in DATA_DIR.iterdir() if d.is_dir() and not d.name.startswith(\".\")])\n",
    "print(f\"\\nMAP folders found: {[d.name for d in map_dirs]}\")\n",
    "for md in map_dirs:\n",
    "    tifs = list(md.glob(\"*.tif\")) + list(md.glob(\"*.tiff\"))\n",
    "    missing = [task for pat, task in SHP_PATTERNS if not list(md.glob(pat))]\n",
    "    status = f\"TIF={len(tifs)}  missing_shp={missing if missing else 'none'}\"\n",
    "    print(f\"  {md.name}: {status}\")\n",
    "\n",
    "# \u2500\u2500 Shared training config \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
    "TARGET_KEYS = [\n",
    "    \"building_mask\", \"road_mask\", \"road_centerline_mask\",\n",
    "    \"waterbody_mask\", \"waterbody_line_mask\", \"waterbody_point_mask\",\n",
    "    \"utility_line_mask\", \"utility_poly_mask\",\n",
    "    \"bridge_mask\", \"railway_mask\", \"roof_type_mask\",\n",
    "]\n",
    "\n",
    "CONFIG = dict(\n",
    "    backbone         = \"resnet50\",\n",
    "    pretrained       = False,   # no external URL downloads on DGX\n",
    "    image_size       = 512,\n",
    "    batch_size       = 8,      # A100 80GB \u2014 increase to 24 if memory allows\n",
    "    epochs_per_map   = 50,\n",
    "    learning_rate    = 2e-4,\n",
    "    weight_decay     = 1e-4,\n",
    "    num_workers      = 0,\n",
    "    mixed_precision  = True,\n",
    "    gradient_clip    = 1.0,\n",
    "    # Loss weights\n",
    "    building_weight        = 1.0,\n",
    "    roof_weight            = 0.5,\n",
    "    road_weight            = 0.8,\n",
    "    waterbody_weight       = 0.8,\n",
    "    road_centerline_weight = 0.7,\n",
    "    waterbody_line_weight  = 0.7,\n",
    "    waterbody_point_weight = 0.9,\n",
    "    utility_line_weight    = 0.7,\n",
    "    utility_poly_weight    = 0.8,\n",
    "    bridge_weight          = 1.0,\n",
    "    railway_weight         = 0.9,\n",
    ")\n",
    "\n",
    "print(\"\\nConfig ready \u2713\")\n",
    "\n",
    "# \u2500\u2500 Helper: train one MAP \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
    "from models.feature_extractor import FeatureExtractorModel\n",
    "from models.losses import MultiTaskLoss\n",
    "from training.metrics import MetricTracker\n",
    "from data.dataset import SvamitvaDataset\n",
    "from data.augmentation import get_train_transforms\n",
    "\n",
    "def move_targets(batch):\n",
    "    return {k: batch[k].to(device) for k in TARGET_KEYS if k in batch}\n",
    "\n",
    "\n",
    "def build_model(load_from: Path = None):\n",
    "    \"\"\"Create the model, optionally loading weights from a previous MAP.\"\"\"\n",
    "    m = FeatureExtractorModel(\n",
    "        backbone=CONFIG[\"backbone\"],\n",
    "        pretrained=CONFIG[\"pretrained\"],\n",
    "        num_roof_classes=5,\n",
    "    )\n",
    "    if load_from and load_from.exists():\n",
    "        state = torch.load(load_from, map_location=\"cpu\")\n",
    "        m.load_state_dict(state[\"model\"])\n",
    "        print(f\"Loaded weights from: {load_from.name}\")\n",
    "        print(f\"  Trained on: {state.get('map_name','?')}  \"\n",
    "              f\"epoch={state.get('epoch','?')}  \"\n",
    "              f\"best_iou={state.get('best_iou',0):.4f}\")\n",
    "    else:\n",
    "        print(\"Starting from random initialisation (no prior checkpoint)\")\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        m = nn.DataParallel(m)\n",
    "    return m.to(device)\n",
    "\n",
    "\n",
    "def train_map(map_name: str, resume_from: Path = None):\n",
    "    \"\"\"\n",
    "    Train for CONFIG['epochs_per_map'] epochs on the given MAP.\n",
    "    resume_from: path to a previous MAP's best.pt (to load its weights).\n",
    "    Returns path to this MAP's best.pt.\n",
    "    \"\"\"\n",
    "    map_dir  = DATA_DIR / map_name\n",
    "    best_out = CKPT_DIR / f\"{map_name}_best.pt\"\n",
    "    last_out = CKPT_DIR / f\"{map_name}_latest.pt\"\n",
    "\n",
    "    assert map_dir.exists(), f\"MAP folder not found: {map_dir}\"\n",
    "\n",
    "    print(f\"\\n{'='*65}\")\n",
    "    print(f\"  Training on: {map_name}\")\n",
    "    print(f\"  Loading weights from: {resume_from.name if resume_from and resume_from.exists() else 'scratch'}\")\n",
    "    print(f\"{'='*65}\")\n",
    "\n",
    "    # \u2500\u2500 Model \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
    "    model_w   = build_model(load_from=resume_from)\n",
    "    inner     = model_w.module if isinstance(model_w, nn.DataParallel) else model_w\n",
    "\n",
    "    # \u2500\u2500 Data \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
    "    ds = SvamitvaDataset(\n",
    "        root_dir   = DATA_DIR,\n",
    "        image_size = CONFIG[\"image_size\"],\n",
    "        transform  = get_train_transforms(CONFIG[\"image_size\"]),\n",
    "        mode       = \"train\",\n",
    "    )\n",
    "    ds.samples = [s for s in ds.samples if s[\"map_name\"] == map_name]\n",
    "    assert ds.samples, f\"No samples found for {map_name} in {DATA_DIR}\"\n",
    "    print(f\"  Tiles: {len(ds)}\")\n",
    "\n",
    "    loader = DataLoader(\n",
    "        ds,\n",
    "        batch_size  = CONFIG[\"batch_size\"],\n",
    "        shuffle     = True,\n",
    "        num_workers = CONFIG[\"num_workers\"],\n",
    "        pin_memory  = True,\n",
    "        drop_last   = len(ds) > CONFIG[\"batch_size\"],\n",
    "    )\n",
    "\n",
    "    # \u2500\u2500 Loss / optimiser / scheduler \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
    "    loss_fn = MultiTaskLoss(\n",
    "        **{k: v for k, v in CONFIG.items() if k.endswith(\"_weight\")}\n",
    "    ).to(device)\n",
    "\n",
    "    optimizer = torch.optim.AdamW(\n",
    "        model_w.parameters(),\n",
    "        lr=CONFIG[\"learning_rate\"],\n",
    "        weight_decay=CONFIG[\"weight_decay\"],\n",
    "    )\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "        optimizer, T_max=CONFIG[\"epochs_per_map\"], eta_min=1e-6\n",
    "    )\n",
    "    scaler = GradScaler('cuda', enabled=CONFIG['mixed_precision'])\n",
    "\n",
    "    # \u2500\u2500 Training loop \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
    "    best_iou  = 0.0\n",
    "    log_lines = []\n",
    "\n",
    "    for epoch in range(1, CONFIG[\"epochs_per_map\"] + 1):\n",
    "        model_w.train()\n",
    "        tracker  = MetricTracker()\n",
    "        run_loss = 0.0\n",
    "        n_steps  = 0\n",
    "        t0       = time.time()\n",
    "\n",
    "        for batch in loader:\n",
    "            images  = batch[\"image\"].to(device)\n",
    "            targets = move_targets(batch)\n",
    "            optimizer.zero_grad()\n",
    "            with autocast('cuda', enabled=CONFIG['mixed_precision']):\n",
    "                preds         = model_w(images)\n",
    "                total_loss, loss_dict = loss_fn(preds, targets)\n",
    "            # \u2500\u2500 NaN Guard: check BEFORE backward to protect backbone \u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
    "            if torch.isnan(total_loss) or torch.isinf(total_loss):\n",
    "                bad = [k for k, v in loss_dict.items() if torch.isnan(v) or torch.isinf(v)]\n",
    "                print(f\"      [NaN SKIP] bad heads={bad}\")\n",
    "                optimizer.zero_grad()  # clear any pending gradient state\n",
    "                continue               # skip backward entirely\n",
    "            scaler.scale(total_loss).backward()\n",
    "            if CONFIG[\"gradient_clip\"] > 0:\n",
    "                scaler.unscale_(optimizer)\n",
    "                nn.utils.clip_grad_norm_(model_w.parameters(), CONFIG[\"gradient_clip\"])\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            run_loss += total_loss.item()\n",
    "            tracker.update(preds, targets)\n",
    "            n_steps += 1\n",
    "\n",
    "        scheduler.step()\n",
    "        m        = tracker.compute()\n",
    "        avg_loss = run_loss / max(n_steps, 1)\n",
    "        avg_iou  = m.get(\"avg_iou\", 0.0)\n",
    "        lr_now   = scheduler.get_last_lr()[0]\n",
    "\n",
    "        line = (f\"  Epoch {epoch:3d}/{CONFIG['epochs_per_map']}  \"\n",
    "                f\"loss={avg_loss:.4f}  avg_iou={avg_iou:.4f}  \"\n",
    "                f\"lr={lr_now:.2e}  t={time.time()-t0:.0f}s\")\n",
    "        print(line)\n",
    "        log_lines.append(line)\n",
    "\n",
    "        # \u2500\u2500 Checkpoint \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
    "        ckpt = {\n",
    "            \"model\"    : inner.state_dict(),\n",
    "            \"epoch\"    : epoch,\n",
    "            \"map_name\" : map_name,\n",
    "            \"avg_iou\"  : avg_iou,\n",
    "            \"best_iou\" : best_iou,\n",
    "            \"metrics\"  : m,\n",
    "            \"config\"   : CONFIG,\n",
    "        }\n",
    "        torch.save(ckpt, last_out)   # always overwrite latest\n",
    "\n",
    "        if avg_iou > best_iou:\n",
    "            best_iou = avg_iou\n",
    "            ckpt[\"best_iou\"] = best_iou\n",
    "            torch.save(ckpt, best_out)  # save best\n",
    "            print(f\"    \u2605 Best checkpoint updated  ({map_name}_best.pt  iou={best_iou:.4f})\")\n",
    "\n",
    "    # Save epoch log\n",
    "    log_path = NOTEBOOK_DIR / \"logs\" / f\"{map_name}_training.log\"\n",
    "    log_path.write_text(\"\\n\".join(log_lines))\n",
    "\n",
    "    print(f\"\\n  {map_name} done.  Best IoU={best_iou:.4f}\")\n",
    "    print(f\"  Best checkpoint : {best_out}\")\n",
    "    print(f\"  Training log    : {log_path}\")\n",
    "    return best_out\n",
    "\n",
    "\n",
    "def analyse_checkpoint(ckpt_path: Path, map_name: str = None):\n",
    "    \"\"\"Print a summary of a saved checkpoint.\"\"\"\n",
    "    assert ckpt_path.exists(), f\"Not found: {ckpt_path}\"\n",
    "    st = torch.load(ckpt_path, map_location=\"cpu\")\n",
    "    m  = st.get(\"metrics\", {})\n",
    "    print(f\"\\n{'\u2500'*60}\")\n",
    "    print(f\"  Checkpoint : {ckpt_path.name}\")\n",
    "    print(f\"  MAP trained: {st.get('map_name','?')}  \"\n",
    "          f\"epoch={st.get('epoch','?')}  \"\n",
    "          f\"best_iou={st.get('best_iou',0):.4f}\")\n",
    "    print(f\"  avg_iou    : {m.get('avg_iou',0):.4f}\")\n",
    "    print(f\"  Per-task IoU:\")\n",
    "    for k, v in m.items():\n",
    "        if k.endswith(\"_iou\") and k != \"avg_iou\":\n",
    "            bar = \"\u2588\" * int(v * 20)\n",
    "            print(f\"    {k:30s} {v:.4f}  {bar}\")\n",
    "    print(f\"{'\u2500'*60}\\n\")\n",
    "\n",
    "print(\"\\nAll helpers ready. Proceed to MAP1 training cell.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83a239f8",
   "metadata": {},
   "source": [
    "---\n",
    "## CELL 2 \u2014 Train MAP1 (from scratch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7199dd7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "map1_best = train_map(\"MAP1\", resume_from=None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f516287",
   "metadata": {},
   "source": [
    "## CELL 3 \u2014 Analyse MAP1 Weights\n",
    "\n",
    "Review per-task IoU before proceeding to MAP2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c6cdda",
   "metadata": {},
   "outputs": [],
   "source": [
    "map1_best = CKPT_DIR / \"MAP1_best.pt\"\n",
    "analyse_checkpoint(map1_best)\n",
    "\n",
    "# Optional: view training loss curve\n",
    "log = (NOTEBOOK_DIR / \"logs\" / \"MAP1_training.log\").read_text()\n",
    "print(\"Last 10 epochs:\")\n",
    "for line in log.strip().split(\"\\n\")[-10:]:\n",
    "    print(line)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adffb211",
   "metadata": {},
   "source": [
    "---\n",
    "## CELL 4 \u2014 Train MAP2 (from MAP1 weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db958d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "map2_best = train_map(\"MAP2\", resume_from=CKPT_DIR / \"MAP1_best.pt\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e62792",
   "metadata": {},
   "source": [
    "## CELL 5 \u2014 Analyse MAP2 Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda411d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyse_checkpoint(CKPT_DIR / \"MAP2_best.pt\")\n",
    "log = (NOTEBOOK_DIR / \"logs\" / \"MAP2_training.log\").read_text()\n",
    "print(\"Last 10 epochs:\")\n",
    "for line in log.strip().split(\"\\n\")[-10:]: print(line)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab7a4d3",
   "metadata": {},
   "source": [
    "---\n",
    "## CELL 6 \u2014 Train MAP3 (from MAP2 weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e2eb03",
   "metadata": {},
   "outputs": [],
   "source": [
    "map3_best = train_map(\"MAP3\", resume_from=CKPT_DIR / \"MAP2_best.pt\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f3dd5f",
   "metadata": {},
   "source": [
    "## CELL 7 \u2014 Analyse MAP3 Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd27a666",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyse_checkpoint(CKPT_DIR / \"MAP3_best.pt\")\n",
    "log = (NOTEBOOK_DIR / \"logs\" / \"MAP3_training.log\").read_text()\n",
    "print(\"Last 10 epochs:\")\n",
    "for line in log.strip().split(\"\\n\")[-10:]: print(line)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fcbc03f",
   "metadata": {},
   "source": [
    "---\n",
    "## CELL 8 \u2014 Train MAP4 (from MAP3 weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a009ff70",
   "metadata": {},
   "outputs": [],
   "source": [
    "map4_best = train_map(\"MAP4\", resume_from=CKPT_DIR / \"MAP3_best.pt\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c187f5f6",
   "metadata": {},
   "source": [
    "## CELL 9 \u2014 Analyse MAP4 Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67363515",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyse_checkpoint(CKPT_DIR / \"MAP4_best.pt\")\n",
    "log = (NOTEBOOK_DIR / \"logs\" / \"MAP4_training.log\").read_text()\n",
    "print(\"Last 10 epochs:\")\n",
    "for line in log.strip().split(\"\\n\")[-10:]: print(line)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "769bb5ca",
   "metadata": {},
   "source": [
    "---\n",
    "## CELL 10 \u2014 Train MAP5 (from MAP4 weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33fe86e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "map5_best = train_map(\"MAP5\", resume_from=CKPT_DIR / \"MAP4_best.pt\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b24960",
   "metadata": {},
   "source": [
    "## CELL 11 \u2014 Analyse MAP5 Weights (Final Universal Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad46a9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyse_checkpoint(CKPT_DIR / \"MAP5_best.pt\")\n",
    "log = (NOTEBOOK_DIR / \"logs\" / \"MAP5_training.log\").read_text()\n",
    "print(\"Last 10 epochs:\")\n",
    "for line in log.strip().split(\"\\n\")[-10:]: print(line)\n",
    "\n",
    "print(\"\\n\" + \"=\"*65)\n",
    "print(\"TRAINING COMPLETE \u2014 MAP5_best.pt is the final universal model\")\n",
    "print(\"It has learned features from all 5 MAP areas.\")\n",
    "print(\"=\"*65)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c9a0c8",
   "metadata": {},
   "source": [
    "---\n",
    "## CELL 12 \u2014 Inference Preview (any MAP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf1b5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from models.feature_extractor import FeatureExtractorModel\n",
    "from data.preprocessing import OrthophotoPreprocessor\n",
    "\n",
    "# \u2500\u2500 Change these as needed \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
    "PREVIEW_MAP  = \"MAP1\"           # which MAP's TIF to preview\n",
    "CKPT_TO_USE  = \"MAP5_best.pt\"  # which checkpoint to load (use final for best results)\n",
    "\n",
    "ckpt_path = CKPT_DIR / CKPT_TO_USE\n",
    "assert ckpt_path.exists(), f\"Run training first: {ckpt_path}\"\n",
    "\n",
    "state = torch.load(ckpt_path, map_location=device)\n",
    "print(f\"Loaded: {CKPT_TO_USE}  (trained on {state.get('map_name','?')}, best_iou={state.get('best_iou',0):.4f})\")\n",
    "\n",
    "infer = FeatureExtractorModel(\n",
    "    backbone=CONFIG[\"backbone\"], pretrained=False, num_roof_classes=5\n",
    ").to(device)\n",
    "infer.load_state_dict(state[\"model\"])\n",
    "infer.eval()\n",
    "\n",
    "tifs = sorted((DATA_DIR / PREVIEW_MAP).glob(\"*.tif\"))\n",
    "assert tifs, f\"No TIF in {DATA_DIR / PREVIEW_MAP}\"\n",
    "\n",
    "prep  = OrthophotoPreprocessor()\n",
    "image, _ = prep.load_orthophoto(tifs[0], target_size=(512, 512))\n",
    "img_t = torch.from_numpy(image).permute(2, 0, 1).unsqueeze(0).float().to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    preds = infer(img_t)\n",
    "\n",
    "keys = [\"building_mask\", \"road_mask\", \"waterbody_mask\",\n",
    "        \"road_centerline_mask\", \"utility_line_mask\",\n",
    "        \"bridge_mask\", \"railway_mask\"]\n",
    "\n",
    "fig, axes = plt.subplots(2, 4, figsize=(22, 11))\n",
    "axes = axes.flatten()\n",
    "axes[0].imshow(image); axes[0].set_title(f\"{PREVIEW_MAP}: {tifs[0].name}\"); axes[0].axis(\"off\")\n",
    "for i, k in enumerate(keys, 1):\n",
    "    pm = torch.sigmoid(preds[k]).squeeze().cpu().numpy()\n",
    "    axes[i].imshow(pm, cmap=\"jet\", vmin=0, vmax=1)\n",
    "    axes[i].set_title(k.replace(\"_mask\", \"\")); axes[i].axis(\"off\")\n",
    "for j in range(len(keys)+1, len(axes)): axes[j].axis(\"off\")\n",
    "\n",
    "plt.suptitle(f\"Model: {CKPT_TO_USE}  |  Input: {PREVIEW_MAP}/{tifs[0].name}\", fontsize=12)\n",
    "plt.tight_layout()\n",
    "out = CKPT_DIR / f\"{PREVIEW_MAP}_inference_preview.png\"\n",
    "plt.savefig(out, dpi=150, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "print(f\"Saved to {out}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}