{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "intro",
            "metadata": {},
            "source": [
                "# SVAMITVA Feature Extraction — Local Mac Training Pipeline (out.ipynb)\n",
                "\n",
                "**Objective:** Train the model using the explicitly added `Desktop/DATA` folder on your Apple Silicon Mac (MPS).\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "cell1-md",
            "metadata": {},
            "source": [
                "---\n",
                "## CELL 1 — Setup & Environment Configuration (Run Once)\n",
                "This cell dynamically checks variables, imports required codebase files (`feature_extractor.py`, etc.), and allocates Apple Silicon."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "id": "cell1",
            "metadata": {},
            "outputs": [
                {
                    "ename": "ModuleNotFoundError",
                    "evalue": "No module named 'torch'",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
                        "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
                        "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtime\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpathlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnn\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DataLoader\n",
                        "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'torch'"
                    ]
                }
            ],
            "source": [
                "import os\n",
                "import sys\n",
                "import time\n",
                "from pathlib import Path\n",
                "\n",
                "import torch\n",
                "import torch.nn as nn\n",
                "from torch.utils.data import DataLoader\n",
                "\n",
                "# ── Workspace Directory Checking ──────────────────────────────────────────\n",
                "NOTEBOOK_DIR = Path.cwd()\n",
                "if str(NOTEBOOK_DIR) not in sys.path:\n",
                "    sys.path.insert(0, str(NOTEBOOK_DIR))\n",
                "\n",
                "DATA_DIR = Path(\"/Users/aaronr/Desktop/DATA\")\n",
                "\n",
                "CKPT_DIR = NOTEBOOK_DIR / \"checkpoints\"\n",
                "CKPT_DIR.mkdir(parents=True, exist_ok=True)\n",
                "(NOTEBOOK_DIR / \"logs\").mkdir(exist_ok=True)\n",
                "\n",
                "# ── Device Allocation (MPS / CPU) ─────────────────────────────────────────\n",
                "if torch.backends.mps.is_available() and torch.backends.mps.is_built():\n",
                "    device = torch.device(\"mps\")\n",
                "    print(\"Apple Silicon GPU (MPS) successfully acquired ✅\")\n",
                "else:\n",
                "    device = torch.device(\"cpu\")\n",
                "    print(\"Executing on CPU ⚠️\")\n",
                "\n",
                "print(f\"Targeting Dataset: {DATA_DIR} (Exists: {DATA_DIR.exists()})\")\n",
                "\n",
                "# ── Training Configuration ────────────────────────────────────────────────\n",
                "CONFIG = dict(\n",
                "    backbone         = \"resnet50\",\n",
                "    pretrained       = True,   # Automatically fetch generic image weights locally\n",
                "    image_size       = 512,\n",
                "    batch_size       = 4,      # Optimized for Mac Memory\n",
                "    epochs_per_map   = 20,     # Faster local preview\n",
                "    learning_rate    = 2e-4,\n",
                "    weight_decay     = 1e-4,\n",
                "    num_workers      = 0,\n",
                "    mixed_precision  = False,  # MPS AutoCast is unstable\n",
                "    gradient_clip    = 1.0,\n",
                "    \n",
                "    # Priority multi-task loss weightings\n",
                "    building_weight        = 1.0,\n",
                "    roof_weight            = 0.5,\n",
                "    road_weight            = 0.8,\n",
                "    waterbody_weight       = 0.8,\n",
                "    road_centerline_weight = 0.7,\n",
                "    waterbody_line_weight  = 0.7,\n",
                "    waterbody_point_weight = 0.9,\n",
                "    utility_line_weight    = 0.7,\n",
                "    utility_poly_weight    = 0.8,\n",
                "    bridge_weight          = 1.0,\n",
                "    railway_weight         = 0.9,\n",
                ")\n",
                "\n",
                "TARGET_KEYS = [\n",
                "    \"building_mask\", \"road_mask\", \"road_centerline_mask\",\n",
                "    \"waterbody_mask\", \"waterbody_line_mask\", \"waterbody_point_mask\",\n",
                "    \"utility_line_mask\", \"utility_poly_mask\",\n",
                "    \"bridge_mask\", \"railway_mask\", \"roof_type_mask\",\n",
                "]\n",
                "\n",
                "print(\"\\nImports and Configuration Complete ✓\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "cell2-md",
            "metadata": {},
            "source": [
                "---\n",
                "## CELL 2 — Training Engine Core\n",
                "Initializes building blocks from the native `.py` codebase: dataset loading, architecture, logic scaling, focal loss algorithms, backwards passes."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "cell2",
            "metadata": {},
            "outputs": [],
            "source": [
                "from models.feature_extractor import FeatureExtractorModel\n",
                "from models.losses import MultiTaskLoss\n",
                "from training.metrics import MetricTracker\n",
                "from data.dataset import SvamitvaDataset\n",
                "from data.augmentation import get_train_transforms\n",
                "\n",
                "def move_targets(batch):\n",
                "    return {k: batch[k].to(device) for k in TARGET_KEYS if k in batch}\n",
                "\n",
                "def build_model(load_from: Path = None):\n",
                "    m = FeatureExtractorModel(\n",
                "        backbone=CONFIG[\"backbone\"],\n",
                "        pretrained=CONFIG[\"pretrained\"],\n",
                "        num_roof_classes=5,\n",
                "    )\n",
                "    if load_from and load_from.exists():\n",
                "        state = torch.load(load_from, map_location=\"cpu\")\n",
                "        m.load_state_dict(state[\"model\"], strict=False)\n",
                "        print(f\"Loaded weights from checkpoint: {load_from.name}\")\n",
                "    return m.to(device)\n",
                "\n",
                "\n",
                "def train_map(map_name: str, resume_from: Path = None):\n",
                "    map_dir  = DATA_DIR / map_name\n",
                "    best_out = CKPT_DIR / f\"{map_name}_best.pt\"\n",
                "    last_out = CKPT_DIR / f\"{map_name}_latest.pt\"\n",
                "\n",
                "    if not map_dir.exists():\n",
                "        print(f\"[SKIPPING/ERROR] Folder NOT FOUND: {map_dir}\")\n",
                "        return best_out if best_out.exists() else None\n",
                "\n",
                "    print(f\"\\n{'='*70}\")\n",
                "    print(f\"  Training Engine Activating for Region : {map_name}\")\n",
                "    print(f\"  Loading prior state weights           : {resume_from.name if resume_from and resume_from.exists() else 'RANDOM / SCRATCH'}\")\n",
                "    print(f\"{'='*70}\")\n",
                "\n",
                "    # Model, Engine Setup\n",
                "    model_w   = build_model(load_from=resume_from)\n",
                "\n",
                "    # Dataset Setup\n",
                "    try:\n",
                "        ds = SvamitvaDataset(\n",
                "            root_dir   = DATA_DIR,\n",
                "            image_size = CONFIG[\"image_size\"],\n",
                "            transform  = get_train_transforms(CONFIG[\"image_size\"]),\n",
                "            mode       = \"train\",\n",
                "        )\n",
                "        ds.samples = [s for s in ds.samples if s[\"map_name\"] == map_name]\n",
                "        print(f\"  Generated dynamically cached tiles    : {len(ds)}\")\n",
                "    except Exception as e:\n",
                "        print(f\"Failed to load dataset for {map_name}: {e}\")\n",
                "        return None\n",
                "\n",
                "    loader = DataLoader(ds, batch_size=CONFIG[\"batch_size\"], shuffle=True, num_workers=CONFIG[\"num_workers\"], pin_memory=False)\n",
                "\n",
                "    # Loss Setup (Includes BinaryFocalLoss)\n",
                "    loss_fn = MultiTaskLoss(**{k: v for k, v in CONFIG.items() if k.endswith(\"_weight\")}).to(device)\n",
                "    optimizer = torch.optim.AdamW(model_w.parameters(), lr=CONFIG[\"learning_rate\"], weight_decay=CONFIG[\"weight_decay\"])\n",
                "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=CONFIG[\"epochs_per_map\"], eta_min=1e-6)\n",
                "\n",
                "    # Loop\n",
                "    best_iou  = 0.0\n",
                "    for epoch in range(1, CONFIG[\"epochs_per_map\"] + 1):\n",
                "        model_w.train()\n",
                "        tracker  = MetricTracker()\n",
                "        run_loss = 0.0\n",
                "        n_steps  = 0\n",
                "        t0       = time.time()\n",
                "\n",
                "        for batch in loader:\n",
                "            images  = batch[\"image\"].to(device)\n",
                "            targets = move_targets(batch)\n",
                "            optimizer.zero_grad(set_to_none=True)\n",
                "            \n",
                "            # Forward Pass (No AMP on Mac)\n",
                "            preds         = model_w(images)\n",
                "            total_loss, loss_dict = loss_fn(preds, targets)\n",
                "            \n",
                "            # NaN Guard & Backward Pass\n",
                "            if not torch.isfinite(total_loss):\n",
                "                print(f\"      [NaN SKIP] skipping bad gradients in step...\")\n",
                "                continue \n",
                "\n",
                "            total_loss.backward()\n",
                "            if CONFIG[\"gradient_clip\"] > 0:\n",
                "                nn.utils.clip_grad_norm_(model_w.parameters(), CONFIG[\"gradient_clip\"])\n",
                "            optimizer.step()\n",
                "\n",
                "            run_loss += total_loss.item()\n",
                "            tracker.update(preds, targets)\n",
                "            n_steps += 1\n",
                "\n",
                "        scheduler.step()\n",
                "        m        = tracker.compute()\n",
                "        avg_loss = run_loss / max(n_steps, 1)\n",
                "        avg_iou  = m.get(\"avg_iou\", 0.0)\n",
                "\n",
                "        print((f\"  Epoch {epoch:2d}/{CONFIG['epochs_per_map']} | \"\n",
                "               f\"loss: {avg_loss:.4f} | iou: {avg_iou:.4f} | \"\n",
                "               f\"time: {time.time()-t0:.0f}s\"))\n",
                "\n",
                "        # Checkpointing\n",
                "        ckpt = {\n",
                "            \"model\"    : model_w.state_dict(),\n",
                "            \"epoch\"    : epoch,\n",
                "            \"map_name\" : map_name,\n",
                "            \"best_iou\" : best_iou,\n",
                "            \"metrics\"  : m,\n",
                "        }\n",
                "        torch.save(ckpt, last_out)\n",
                "        if avg_iou > best_iou:\n",
                "            best_iou = avg_iou\n",
                "            ckpt[\"best_iou\"] = best_iou\n",
                "            torch.save(ckpt, best_out)\n",
                "            print(f\"    → New Best Checkpoint saved! IoU = {best_iou:.4f}\")\n",
                "\n",
                "    print(f\"\\n  [MAP COMPLETE] {map_name} finished.  Best IoU={best_iou:.4f}\")\n",
                "    return best_out\n",
                "\n",
                "print(\"Training Core Active ✓\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "cell3-md",
            "metadata": {},
            "source": [
                "---\n",
                "## CELL 3 — Executive Training Suite \n",
                "Run this block sequentially. It handles progressive multi-map knowledge assimilation ("
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "cell3",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Execute progressively. It handles missing maps gracefully, carrying over checkpoints across regions \n",
                "cpt1 = train_map(\"MAP1\", resume_from=None)\n",
                "\n",
                "print(\"\\n*** SVAMITVA PIPELINE EXHAUSTED ***\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.13.7"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
