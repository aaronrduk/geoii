{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro",
   "metadata": {},
   "source": [
    "# SVAMITVA â€” DGX Training Pipeline\n",
    "\n",
    "**Target:** DGX Server with Multiple GPUs (CUDA).\n",
    "**DATA path:** `/jupyter/sods.user04/DATA`\n",
    "\n",
    "Automatically discovers `MAP1`, `MAP2`, etc., and trains sequentially inheriting checkpoints (KMeans tile filtering enabled to avoid NoData)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell1-md",
   "metadata": {},
   "source": [
    "---\n",
    "## Cell 1 â€” Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, time, torch\n",
    "from pathlib import Path\n",
    "import logging\n",
    "logging.getLogger().setLevel(logging.WARNING)\n",
    "# =============================================================================== \n",
    "# ðŸ›°ï¸ DGX STABILITY FIX (MULTI-GPU, >40GB FREE)\n",
    "# =============================================================================== \n",
    "def get_free_gpus(min_free_gb=40):\n",
    "    import subprocess\n",
    "    result = subprocess.run(\n",
    "        ['nvidia-smi', '--query-gpu=memory.free', '--format=csv,nounits,noheader'],\n",
    "        stdout=subprocess.PIPE, encoding='utf-8'\n",
    "    )\n",
    "    free_memories = [int(x) for x in result.stdout.strip().split('\\n')]\n",
    "    eligible_gpus = [str(i) for i, mem in enumerate(free_memories) if mem > min_free_gb * 1024]\n",
    "    return eligible_gpus\n",
    "\n",
    "gpu_ids = get_free_gpus()\n",
    "if not gpu_ids:\n",
    "    raise RuntimeError(\"No GPU with >40GB free found.\")\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \",\".join(gpu_ids)\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "\n",
    "# --- ðŸ§¬ ROOT DISCOVERY ---\n",
    "PROJECT_ROOT = Path.cwd()\n",
    "for parent in [PROJECT_ROOT] + list(PROJECT_ROOT.parents):\n",
    "    if (parent / \"models\").exists() or (parent / \"requirements.txt\").exists():\n",
    "        PROJECT_ROOT = parent; break\n",
    "else:\n",
    "    PROJECT_ROOT = Path(\"/svamitva_model\") if Path(\"/svamitva_model\").exists() else Path.cwd()\n",
    "if str(PROJECT_ROOT) not in sys.path: sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "# --- ðŸ“ DIRECTORY SETUP ---\n",
    "DATA_DIR = Path(\"/jupyter/sods.user04/DATA\")\n",
    "if not DATA_DIR.exists(): DATA_DIR = Path(\"/DATA\")\n",
    "CKPT_DIR = Path(\"/jupyter/sods.user04/check\")\n",
    "CKPT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "LOG_DIR  = PROJECT_ROOT / \"logs\"; LOG_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# --- âš™ï¸ DEVICE & CONFIG ---\n",
    "device = torch.device(\"cuda\")\n",
    "CONFIG = dict(\n",
    "    backbone=\"resnet50\", pretrained=True, image_size=512, batch_size=32,\n",
    "    epochs_per_map=50, learning_rate=2e-4, weight_decay=1e-4, num_workers=8,\n",
    "    mixed_precision=True, gradient_clip=1.0,\n",
    "    building_weight=1.0, roof_weight=0.5, road_weight=0.8,\n",
    "    waterbody_weight=0.8, road_centerline_weight=0.7,\n",
    "    waterbody_line_weight=0.7, waterbody_point_weight=0.9,\n",
    "    utility_line_weight=0.7, utility_poly_weight=0.8,\n",
    "    bridge_weight=1.0, railway_weight=0.9,\n",
    ")\n",
    "\n",
    "TARGET_KEYS = [\"building_mask\", \"road_mask\", \"road_centerline_mask\", \"waterbody_mask\", \n",
    "               \"waterbody_line_mask\", \"waterbody_point_mask\", \"utility_line_mask\", \n",
    "               \"utility_poly_mask\", \"bridge_mask\", \"railway_mask\", \"roof_type_mask\"]\n",
    "\n",
    "print(f\"âœ… STABILITY MODE: Using GPUs {gpu_ids} (each >40GB free).\")\n",
    "print(f\"âœ… Setup Complete | Devices: {[torch.cuda.get_device_name(i) for i in range(torch.cuda.device_count())]}\")\n",
    "\n",
    "# When creating your model:\n",
    "# model = ... # your model definition\n",
    "# model = torch.nn.DataParallel(model)  # for multi-GPU training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell2-md",
   "metadata": {},
   "source": [
    "---\n",
    "## Cell 2 â€” Training Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, time, torch, torch.nn as nn\n",
    "from pathlib import Path\n",
    "\n",
    "# --- ðŸ›¡ï¸ SELF-HEALING PATH CHECK (Crucial for imports) ---\n",
    "if 'models' not in sys.modules:\n",
    "    for _p in [Path.cwd()] + list(Path.cwd().parents):\n",
    "        if (_p / \"models\").exists() and (_p / \"models/__init__.py\").exists():\n",
    "            if str(_p) not in sys.path: sys.path.insert(0, str(_p))\n",
    "            break\n",
    "    else:\n",
    "        dgx_path = \"/jupyter/sods.user04/svamitva_model\"\n",
    "        if Path(dgx_path).exists() and dgx_path not in sys.path: \n",
    "            sys.path.insert(0, dgx_path)\n",
    "\n",
    "# --- ðŸ›°ï¸ GPU SELECTION: Use all GPUs with >40GB free ---\n",
    "def get_free_gpus(min_free_gb=40):\n",
    "    import subprocess\n",
    "    result = subprocess.run(\n",
    "        ['nvidia-smi', '--query-gpu=memory.free', '--format=csv,nounits,noheader'],\n",
    "        stdout=subprocess.PIPE, encoding='utf-8'\n",
    "    )\n",
    "    free_memories = [int(x) for x in result.stdout.strip().split('\\n')]\n",
    "    eligible_gpus = [str(i) for i, mem in enumerate(free_memories) if mem > min_free_gb * 1024]\n",
    "    return eligible_gpus\n",
    "\n",
    "gpu_ids = get_free_gpus()\n",
    "if not gpu_ids:\n",
    "    raise RuntimeError(\"No GPU with >40GB free found.\")\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \",\".join(gpu_ids)\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "torch.backends.cudnn.benchmark = True  # <--- Enable cuDNN autotune\n",
    "\n",
    "# --- ðŸ§¬ ROOT DISCOVERY ---\n",
    "PROJECT_ROOT = Path.cwd()\n",
    "for parent in [PROJECT_ROOT] + list(PROJECT_ROOT.parents):\n",
    "    if (parent / \"models\").exists() or (parent / \"requirements.txt\").exists():\n",
    "        PROJECT_ROOT = parent; break\n",
    "else:\n",
    "    PROJECT_ROOT = Path(\"/svamitva_model\") if Path(\"/svamitva_model\").exists() else Path.cwd()\n",
    "\n",
    "if str(PROJECT_ROOT) not in sys.path: sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "# --- ðŸ“ DIRECTORY SETUP ---\n",
    "DATA_DIR = Path(\"/jupyter/sods.user04/DATA\")\n",
    "if not DATA_DIR.exists(): DATA_DIR = Path(\"/DATA\")\n",
    "CKPT_DIR = Path(\"/jupyter/sods.user04/check\")  # Ensure this is the correct, writable path\n",
    "CKPT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "LOG_DIR  = PROJECT_ROOT / \"logs\"; LOG_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# --- âš™ï¸ DEVICE & CONFIG ---\n",
    "CONFIG = dict(\n",
    "    backbone=\"resnet50\", pretrained=True, image_size=512, batch_size=32,\n",
    "    epochs_per_map=50, learning_rate=2e-4, weight_decay=1e-4, num_workers=8,\n",
    "    mixed_precision=True, gradient_clip=1.0,\n",
    "    building_weight=1.0, roof_weight=0.5, road_weight=0.8,\n",
    "    waterbody_weight=0.8, road_centerline_weight=0.7,\n",
    "    waterbody_line_weight=0.7, waterbody_point_weight=0.9,\n",
    "    utility_line_weight=0.7, utility_poly_weight=0.8,\n",
    "    bridge_weight=1.0, railway_weight=0.9,\n",
    ")\n",
    "\n",
    "TARGET_KEYS = [\"building_mask\", \"road_mask\", \"road_centerline_mask\", \"waterbody_mask\", \n",
    "               \"waterbody_line_mask\", \"waterbody_point_mask\", \"utility_line_mask\", \n",
    "               \"utility_poly_mask\", \"bridge_mask\", \"railway_mask\", \"roof_type_mask\"]\n",
    "\n",
    "# --- ðŸ“¦ IMPORTS ---\n",
    "from torch.utils.data import DataLoader\n",
    "try: from torch.amp import GradScaler, autocast\n",
    "except: from torch.cuda.amp import GradScaler, autocast\n",
    "\n",
    "from models.feature_extractor import FeatureExtractor\n",
    "from models.losses import MultiTaskLoss\n",
    "from training.metrics import MetricTracker\n",
    "from data.dataset import SvamitvaDataset\n",
    "from data.augmentation import get_train_transforms\n",
    "\n",
    "def move_targets(batch):\n",
    "    return {k: v.to(device) for k, v in batch.items() if k in TARGET_KEYS}\n",
    "\n",
    "def build_model(load_from: Path = None):\n",
    "    m = FeatureExtractor(backbone=CONFIG[\"backbone\"], pretrained=True, num_roof_classes=5)\n",
    "    if load_from and load_from.exists():\n",
    "        state = torch.load(load_from, map_location=\"cpu\", weights_only=False)\n",
    "        weights = state.get(\"model\") or state.get(\"model_state_dict\") or state\n",
    "        m.load_state_dict(weights, strict=False)\n",
    "    # Wrap model for multi-GPU\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        m = nn.DataParallel(m)\n",
    "    return m.to(device)\n",
    "\n",
    "def train_map(map_name: str, resume_from: Path = None):\n",
    "    torch.cuda.empty_cache()\n",
    "    map_dir = DATA_DIR / map_name\n",
    "    best_out, last_out = CKPT_DIR / f\"{map_name}_best.pt\", CKPT_DIR / f\"{map_name}_latest.pt\"\n",
    "    if not map_dir.exists(): return best_out if best_out.exists() else None\n",
    "\n",
    "    print(f\"\\n{'='*70}\\n  Region     : {map_name}\\n  Isolation  : GPUs {gpu_ids}\\n{'='*70}\")\n",
    "    model_w = build_model(load_from=resume_from)\n",
    "    \n",
    "    try:\n",
    "        ds = SvamitvaDataset(root_dir=DATA_DIR, image_size=512, transform=get_train_transforms(512), mode=\"train\")\n",
    "        ds.samples = [s for s in ds.samples if s[\"map_name\"] == map_name]\n",
    "        loader = DataLoader(ds, batch_size=CONFIG[\"batch_size\"], shuffle=True, num_workers=CONFIG[\"num_workers\"], pin_memory=True)\n",
    "    except Exception as e: print(f\"Data Fail: {e}\"); return None\n",
    "\n",
    "    loss_fn = MultiTaskLoss(**{k: v for k, v in CONFIG.items() if k.endswith(\"_weight\")}).to(device)\n",
    "    optimizer = torch.optim.AdamW(model_w.parameters(), lr=CONFIG[\"learning_rate\"], weight_decay=CONFIG[\"weight_decay\"])\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=50, eta_min=1e-6)\n",
    "    scaler = GradScaler(enabled=True)\n",
    "\n",
    "    best_iou = 0.0\n",
    "    try:\n",
    "        for epoch in range(1, 51):\n",
    "            model_w.train()\n",
    "            tracker, run_loss, n_steps, t0 = MetricTracker(), 0.0, 0, time.time()\n",
    "            for batch in loader:\n",
    "                imgs, targets = batch[\"image\"].to(device, non_blocking=True), move_targets(batch)\n",
    "                optimizer.zero_grad(set_to_none=True)\n",
    "                with autocast(device_type=\"cuda\", enabled=True):\n",
    "                    preds = model_w(imgs); total_loss, _ = loss_fn(preds, targets)\n",
    "                if not torch.isfinite(total_loss): continue\n",
    "                scaler.scale(total_loss).backward(); scaler.step(optimizer); scaler.update()\n",
    "                run_loss += total_loss.item(); tracker.update(preds, targets); n_steps += 1\n",
    "            \n",
    "            scheduler.step()\n",
    "            avg_iou = tracker.compute().get(\"avg_iou\", 0.0)\n",
    "            print(f\"  Epoch {epoch:2d} | loss: {run_loss/max(n_steps,1):.4f} | iou: {avg_iou:.4f} | {time.time()-t0:.0f}s\")\n",
    "            print(f\"Saving checkpoint to: {last_out}\")\n",
    "            torch.save(model_w.state_dict(), last_out)\n",
    "            print(f\"Checkpoint saved: {last_out}\")  # <-- Live update print\n",
    "            if avg_iou > best_iou:\n",
    "                best_iou = avg_iou\n",
    "                print(f\"Saving best checkpoint to: {best_out}\")\n",
    "                torch.save(model_w.state_dict(), best_out)\n",
    "                print(f\"Best checkpoint saved: {best_out}\")  # <-- Live update print\n",
    "    except (Exception, KeyboardInterrupt) as e:\n",
    "        print(f\"\\nâš ï¸ EMERGENCY SAVE: {e}\")\n",
    "        torch.save(model_w.state_dict(), last_out.with_suffix(\".crash_backup.pt\"))\n",
    "        print(f\"Crash backup saved: {last_out.with_suffix('.crash_backup.pt')}\")\n",
    "        raise e\n",
    "    return best_out\n",
    "\n",
    "print(f\"âœ… Logic Ready & Modules Imported | Using GPUs: {gpu_ids}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell3-md",
   "metadata": {},
   "source": [
    "---\n",
    "## Cell 3 â€” Execute Training\n",
    "Sequential multi-map training. Iterates through all available DGX MAP folders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import sys\n",
    "import re\n",
    "\n",
    "def auto_train_all():\n",
    "    # Discover MAP folders\n",
    "    map_folders = sorted([\n",
    "        d.name for d in DATA_DIR.iterdir()\n",
    "        if d.is_dir() and d.name.startswith(\"MAP\") and not d.name.startswith(\".\")\n",
    "    ])\n",
    "    print(f\"ðŸš€ Training {len(map_folders)} maps sequentially: {map_folders}\")\n",
    "\n",
    "    prev_ckpt, summary = None, []\n",
    "    for m_name in map_folders:\n",
    "        print(f\"â³ Training {m_name}... \", end=\"\", flush=True)\n",
    "        buffer = io.StringIO()\n",
    "        old_out, old_err = sys.stdout, sys.stderr\n",
    "        sys.stdout = sys.stderr = buffer\n",
    "        err_msg = None\n",
    "        try:\n",
    "            ckpt = train_map(m_name, resume_from=prev_ckpt)\n",
    "        except Exception as e:\n",
    "            ckpt = None\n",
    "            err_msg = str(e)\n",
    "        finally:\n",
    "            sys.stdout = old_out\n",
    "            sys.stderr = old_err\n",
    "\n",
    "        logs = buffer.getvalue().splitlines()\n",
    "        # Preprocessing progress: only show total/completed pixels and percentage\n",
    "        total_pixels = None\n",
    "        completed_pixels = 0\n",
    "        for line in logs:\n",
    "            m = re.search(r\"tiles from (MAP\\d+) \\((\\d+)Ã—(\\d+)px\\)\", line)\n",
    "            if m:\n",
    "                total_pixels = int(m.group(2)) * int(m.group(3))\n",
    "            m2 = re.search(r\"mask positive pixels: (\\d+)\", line)\n",
    "            if m2 and total_pixels:\n",
    "                completed_pixels += int(m2.group(1))\n",
    "                percent = int(completed_pixels / max(total_pixels, 1) * 100)\n",
    "                print(f\"   Preprocessing: {completed_pixels}/{total_pixels} px ({percent}%)\")\n",
    "\n",
    "        # Show percentage progress for each epoch\n",
    "        epoch_lines = [l for l in logs if \"Epoch\" in l and \"/\" in l]\n",
    "        for line in epoch_lines:\n",
    "            m = re.search(r\"Epoch (\\d+)/(\\d+)\", line)\n",
    "            if m:\n",
    "                cur, total = int(m.group(1)), int(m.group(2))\n",
    "                percent = int(cur / max(total, 1) * 100)\n",
    "                print(f\"   Progress: Epoch {cur}/{total} ({percent}%)\")\n",
    "\n",
    "        # Show checkpoint saving/updating\n",
    "        for line in logs:\n",
    "            if \"checkpoint saved\" in line or \"Saving emergency checkpoint\" in line or \"New best!\" in line:\n",
    "                print(f\"   {line}\")\n",
    "\n",
    "        # After training, print only the final result for this map\n",
    "        if ckpt and ckpt.exists():\n",
    "            print(\"âœ… SUCCESS\")\n",
    "            summary.append(f\"{m_name}: OK\")\n",
    "            prev_ckpt = ckpt\n",
    "        else:\n",
    "            print(\"âŒ FAILED\")\n",
    "            summary.append(f\"{m_name}: FAIL\")\n",
    "            if err_msg:\n",
    "                print(f\"   Reason: {err_msg}\")\n",
    "            error_lines = [l for l in logs if \"ERROR\" in l or \"Exception\" in l or \"FAILED\" in l]\n",
    "            if error_lines:\n",
    "                print(\"   Error log:\")\n",
    "                for l in error_lines[-5:]:\n",
    "                    print(f\"   {l}\")\n",
    "            break\n",
    "\n",
    "    print(\"\\n   *** SEQUENTIAL DGX TRAINING COMPLETE ***\")\n",
    "    for s in summary:\n",
    "        print(f\" - {s}\")\n",
    "\n",
    "auto_train_all()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.14.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
