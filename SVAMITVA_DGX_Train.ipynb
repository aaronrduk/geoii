{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro",
   "metadata": {},
   "source": [
    "# SVAMITVA ‚Äî DGX Training Pipeline (MAPC Sub-Maps)\n",
    "\n",
    "**Target:** DGX Server ‚Äî single GPU with the most free VRAM.\n",
    "**DATA path:** `/jupyter/sods.user04/DATA/MAPC` (pre-clipped 512√ó512 sub-maps)\n",
    "**Checkpoints:** `/jupyter/sods.user04/check/MAP_best.pt` / `MAP_latest.pt`\n",
    "\n",
    "Trains each sub-map (MAP1.1, MAP1.2, ‚Ä¶) individually in sequence. One global checkpoint. Asks permission before moving to next parent map."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell1-md",
   "metadata": {},
   "source": [
    "---\n",
    "## Cell 1 ‚Äî Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, time, torch\n",
    "import torch.nn as nn\n",
    "from pathlib import Path\n",
    "\n",
    "# =============================================================================== \n",
    "# üõ∞Ô∏è DGX ‚Äî SELECT GPU WITH MOST FREE MEMORY\n",
    "# =============================================================================== \n",
    "def get_best_gpu():\n",
    "    \"\"\"Return the index of the single GPU with the most free VRAM.\"\"\"\n",
    "    import subprocess\n",
    "    result = subprocess.run(\n",
    "        ['nvidia-smi', '--query-gpu=memory.free', '--format=csv,nounits,noheader'],\n",
    "        stdout=subprocess.PIPE, encoding='utf-8'\n",
    "    )\n",
    "    free_memories = [int(x) for x in result.stdout.strip().split('\\n')]\n",
    "    best_idx = max(range(len(free_memories)), key=lambda i: free_memories[i])\n",
    "    free_gb = free_memories[best_idx] / 1024\n",
    "    print(f\"   GPU {best_idx} selected ‚Äî {free_gb:.1f} GB free (max of {len(free_memories)} GPUs)\")\n",
    "    return str(best_idx)\n",
    "\n",
    "gpu_id = get_best_gpu()\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = gpu_id\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "\n",
    "# --- üß¨ ROOT DISCOVERY ---\n",
    "PROJECT_ROOT = Path.cwd()\n",
    "for parent in [PROJECT_ROOT] + list(PROJECT_ROOT.parents):\n",
    "    if (parent / \"models\").exists() or (parent / \"requirements.txt\").exists():\n",
    "        PROJECT_ROOT = parent\n",
    "        break\n",
    "else:\n",
    "    PROJECT_ROOT = Path(\"/svamitva_model\") if Path(\"/svamitva_model\").exists() else Path.cwd()\n",
    "if str(PROJECT_ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "# --- üìÅ DIRECTORY SETUP ---\n",
    "DATA_DIR = Path(\"/jupyter/sods.user04/DATA/MAPC\")\n",
    "if not DATA_DIR.exists():\n",
    "    DATA_DIR = Path(\"/DATA/MAPC\")\n",
    "CKPT_DIR = Path(\"/jupyter/sods.user04/check\")\n",
    "CKPT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "LOG_DIR = PROJECT_ROOT / \"logs\"\n",
    "LOG_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# --- ‚öôÔ∏è DEVICE & CONFIG ---\n",
    "device = torch.device(\"cuda\")\n",
    "CONFIG = dict(\n",
    "    backbone=\"resnet50\", pretrained=True, image_size=512, batch_size=32,\n",
    "    epochs_per_map=50, learning_rate=2e-4, weight_decay=1e-4, num_workers=8,\n",
    "    mixed_precision=True, gradient_clip=1.0,\n",
    "    building_weight=1.0, roof_weight=0.5, road_weight=0.8,\n",
    "    waterbody_weight=0.8, road_centerline_weight=0.7,\n",
    "    waterbody_line_weight=0.7, waterbody_point_weight=0.9,\n",
    "    utility_line_weight=0.7, utility_poly_weight=0.8,\n",
    "    bridge_weight=1.0, railway_weight=0.9,\n",
    ")\n",
    "\n",
    "TARGET_KEYS = [\n",
    "    \"building_mask\", \"road_mask\", \"road_centerline_mask\", \"waterbody_mask\",\n",
    "    \"waterbody_line_mask\", \"waterbody_point_mask\", \"utility_line_mask\",\n",
    "    \"utility_poly_mask\", \"bridge_mask\", \"railway_mask\", \"roof_type_mask\"\n",
    "]\n",
    "\n",
    "print(f\"‚úÖ Setup Complete | GPU {gpu_id}: {torch.cuda.get_device_name(0)}\")\n",
    "\n",
    "# Ensure models import works (check for __init__.py)\n",
    "for parent in [PROJECT_ROOT] + list(PROJECT_ROOT.parents):\n",
    "    if (parent / \"models\").exists() and (parent / \"models/__init__.py\").exists():\n",
    "        if str(parent) not in sys.path:\n",
    "            sys.path.insert(0, str(parent))\n",
    "        break\n",
    "\n",
    "print(\"sys.path:\", sys.path)  # Debug: see where Python is searching\n",
    "from models.feature_extractor import FeatureExtractor\n",
    "\n",
    "def build_model(load_from: Path = None):\n",
    "    m = FeatureExtractor(backbone=CONFIG[\"backbone\"], pretrained=True, num_roof_classes=5)\n",
    "    if load_from and load_from.exists():\n",
    "        state = torch.load(load_from, map_location=\"cpu\", weights_only=False)\n",
    "        weights = state.get(\"model\") or state.get(\"model_state_dict\") or state\n",
    "        m.load_state_dict(weights, strict=False)\n",
    "    return m.to(device)\n",
    "\n",
    "# Usage:\n",
    "model = build_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell2-md",
   "metadata": {},
   "source": [
    "---\n",
    "## Cell 2 ‚Äî Training Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, time, torch, torch.nn as nn\n",
    "from pathlib import Path\n",
    "\n",
    "# --- üõ°Ô∏è SELF-HEALING PATH CHECK (Crucial for imports) ---\n",
    "if 'models' not in sys.modules:\n",
    "    for _p in [Path.cwd()] + list(Path.cwd().parents):\n",
    "        if (_p / \"models\").exists() and (_p / \"models/__init__.py\").exists():\n",
    "            if str(_p) not in sys.path: sys.path.insert(0, str(_p))\n",
    "            break\n",
    "    else:\n",
    "        dgx_path = \"/jupyter/sods.user04/svamitva_model\"\n",
    "        if Path(dgx_path).exists() and dgx_path not in sys.path: \n",
    "            sys.path.insert(0, dgx_path)\n",
    "\n",
    "# --- üõ∞Ô∏è GPU SELECTION: Single GPU with the most free VRAM ---\n",
    "def get_best_gpu():\n",
    "    import subprocess\n",
    "    result = subprocess.run(\n",
    "        ['nvidia-smi', '--query-gpu=memory.free', '--format=csv,nounits,noheader'],\n",
    "        stdout=subprocess.PIPE, encoding='utf-8'\n",
    "    )\n",
    "    free_memories = [int(x) for x in result.stdout.strip().split('\\n')]\n",
    "    best_idx = max(range(len(free_memories)), key=lambda i: free_memories[i])\n",
    "    free_gb = free_memories[best_idx] / 1024\n",
    "    print(f\"   GPU {best_idx} selected ‚Äî {free_gb:.1f} GB free (max of {len(free_memories)} GPUs)\")\n",
    "    return str(best_idx)\n",
    "\n",
    "gpu_id = get_best_gpu()\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = gpu_id\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "# --- üß¨ ROOT DISCOVERY ---\n",
    "PROJECT_ROOT = Path.cwd()\n",
    "for parent in [PROJECT_ROOT] + list(PROJECT_ROOT.parents):\n",
    "    if (parent / \"models\").exists() or (parent / \"requirements.txt\").exists():\n",
    "        PROJECT_ROOT = parent; break\n",
    "else:\n",
    "    PROJECT_ROOT = Path(\"/svamitva_model\") if Path(\"/svamitva_model\").exists() else Path.cwd()\n",
    "\n",
    "if str(PROJECT_ROOT) not in sys.path: sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "# --- üìÅ DIRECTORY SETUP (MAPC sub-maps) ---\n",
    "DATA_DIR = Path(\"/jupyter/sods.user04/DATA/MAPC\")\n",
    "if not DATA_DIR.exists(): DATA_DIR = Path(\"/DATA/MAPC\")\n",
    "CKPT_DIR = Path(\"/jupyter/sods.user04/check\")\n",
    "CKPT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "LOG_DIR  = PROJECT_ROOT / \"logs\"; LOG_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# --- Single global checkpoint files ---\n",
    "BEST_CKPT = CKPT_DIR / \"MAP_best.pt\"\n",
    "LATEST_CKPT = CKPT_DIR / \"MAP_latest.pt\"\n",
    "\n",
    "# --- ‚öôÔ∏è DEVICE & CONFIG ---\n",
    "CONFIG = dict(\n",
    "    backbone=\"resnet50\", pretrained=True, image_size=512, batch_size=32,\n",
    "    epochs_per_map=50, learning_rate=2e-4, weight_decay=1e-4, num_workers=8,\n",
    "    mixed_precision=True, gradient_clip=1.0,\n",
    "    building_weight=1.0, roof_weight=0.5, road_weight=0.8,\n",
    "    waterbody_weight=0.8, road_centerline_weight=0.7,\n",
    "    waterbody_line_weight=0.7, waterbody_point_weight=0.9,\n",
    "    utility_line_weight=0.7, utility_poly_weight=0.8,\n",
    "    bridge_weight=1.0, railway_weight=0.9,\n",
    ")\n",
    "\n",
    "TARGET_KEYS = [\"building_mask\", \"road_mask\", \"road_centerline_mask\", \"waterbody_mask\", \n",
    "               \"waterbody_line_mask\", \"waterbody_point_mask\", \"utility_line_mask\", \n",
    "               \"utility_poly_mask\", \"bridge_mask\", \"railway_mask\", \"roof_type_mask\"]\n",
    "\n",
    "# --- üì¶ IMPORTS ---\n",
    "from torch.utils.data import DataLoader\n",
    "try: from torch.amp import GradScaler, autocast\n",
    "except: from torch.cuda.amp import GradScaler, autocast\n",
    "\n",
    "from models.feature_extractor import FeatureExtractor\n",
    "from models.losses import MultiTaskLoss\n",
    "from training.metrics import MetricTracker\n",
    "from data.dataset import SvamitvaDataset\n",
    "from data.augmentation import get_train_transforms\n",
    "\n",
    "def move_targets(batch):\n",
    "    return {k: v.to(device) for k, v in batch.items() if k in TARGET_KEYS}\n",
    "\n",
    "def build_model(load_from: Path = None):\n",
    "    m = FeatureExtractor(backbone=CONFIG[\"backbone\"], pretrained=True, num_roof_classes=5)\n",
    "    if load_from and load_from.exists():\n",
    "        state = torch.load(load_from, map_location=\"cpu\", weights_only=False)\n",
    "        weights = state.get(\"model\") or state.get(\"model_state_dict\") or state\n",
    "        m.load_state_dict(weights, strict=False)\n",
    "        print(f\"  Loaded weights from: {load_from.name}\")\n",
    "    return m.to(device)\n",
    "\n",
    "\n",
    "def train_submap(sub_name, model_w, optimizer, scheduler, scaler, best_iou):\n",
    "    \"\"\"Train one sub-map (e.g. MAP1.42). Returns updated (model, optimizer, scheduler, scaler, best_iou).\"\"\"\n",
    "    torch.cuda.empty_cache()\n",
    "    sub_dir = DATA_DIR / sub_name\n",
    "    if not sub_dir.exists():\n",
    "        print(f\"    [SKIP] {sub_dir} not found\")\n",
    "        return model_w, optimizer, scheduler, scaler, best_iou\n",
    "\n",
    "    ds = SvamitvaDataset(root_dir=DATA_DIR, image_size=512, transform=get_train_transforms(512), mode=\"train\")\n",
    "    ds.samples = [s for s in ds.samples if s[\"map_name\"] == sub_name]\n",
    "    if not ds.samples:\n",
    "        print(f\"    [SKIP] {sub_name}: 0 tiles\")\n",
    "        return model_w, optimizer, scheduler, scaler, best_iou\n",
    "\n",
    "    loader = DataLoader(ds, batch_size=CONFIG[\"batch_size\"], shuffle=True,\n",
    "                        num_workers=CONFIG[\"num_workers\"], pin_memory=True)\n",
    "    loss_fn = MultiTaskLoss(**{k: v for k, v in CONFIG.items() if k.endswith(\"_weight\")}).to(device)\n",
    "\n",
    "    for epoch in range(1, CONFIG[\"epochs_per_map\"] + 1):\n",
    "        model_w.train()\n",
    "        tracker, run_loss, n_steps, t0 = MetricTracker(), 0.0, 0, time.time()\n",
    "\n",
    "        for batch in loader:\n",
    "            imgs, targets = batch[\"image\"].to(device, non_blocking=True), move_targets(batch)\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            with autocast(device_type=\"cuda\", enabled=True):\n",
    "                preds = model_w(imgs); total_loss, _ = loss_fn(preds, targets)\n",
    "            if not torch.isfinite(total_loss): continue\n",
    "            scaler.scale(total_loss).backward()\n",
    "            scaler.unscale_(optimizer)\n",
    "            nn.utils.clip_grad_norm_(model_w.parameters(), CONFIG[\"gradient_clip\"])\n",
    "            scaler.step(optimizer); scaler.update()\n",
    "            run_loss += total_loss.item(); tracker.update(preds, targets); n_steps += 1\n",
    "\n",
    "        scheduler.step()\n",
    "        avg_iou = tracker.compute().get(\"avg_iou\", 0.0)\n",
    "        print(f\"    Epoch {epoch:2d}/{CONFIG['epochs_per_map']} | \"\n",
    "              f\"loss: {run_loss/max(n_steps,1):.4f} | iou: {avg_iou:.4f} | {time.time()-t0:.0f}s\")\n",
    "\n",
    "        # Always save latest\n",
    "        torch.save(model_w.state_dict(), LATEST_CKPT)\n",
    "\n",
    "        if avg_iou > best_iou:\n",
    "            best_iou = avg_iou\n",
    "            torch.save(model_w.state_dict(), BEST_CKPT)\n",
    "            print(f\"    ‚Üí New best! IoU = {best_iou:.4f}\")\n",
    "\n",
    "    return model_w, optimizer, scheduler, scaler, best_iou\n",
    "\n",
    "\n",
    "def train_parent_map(parent_map: str, resume_from: Path = None):\n",
    "    \"\"\"Train each sub-map individually in sequence. Saves to MAP_best.pt / MAP_latest.pt.\"\"\"\n",
    "    sub_maps = sorted(\n",
    "        [d.name for d in DATA_DIR.iterdir()\n",
    "         if d.is_dir() and d.name.startswith(parent_map + \".\")],\n",
    "        key=lambda n: int(n.split(\".\")[-1])\n",
    "    )\n",
    "    if not sub_maps:\n",
    "        print(f\"  [SKIP] No sub-maps for {parent_map}\")\n",
    "        return resume_from\n",
    "\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"  Parent map : {parent_map}  ({len(sub_maps)} sub-maps)\")\n",
    "    print(f\"  GPU        : {gpu_id}\")\n",
    "    print(f\"  Sub-maps   : {sub_maps[0]} ‚Üí {sub_maps[-1]}\")\n",
    "    print(f\"  Resume     : {resume_from.name if resume_from and resume_from.exists() else 'SCRATCH'}\")\n",
    "    print(f\"  Saving to  : {BEST_CKPT.name} / {LATEST_CKPT.name}\")\n",
    "    print(f\"{'='*70}\")\n",
    "\n",
    "    model_w = build_model(load_from=resume_from)\n",
    "    optimizer = torch.optim.AdamW(model_w.parameters(), lr=CONFIG[\"learning_rate\"], weight_decay=CONFIG[\"weight_decay\"])\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=CONFIG[\"epochs_per_map\"], eta_min=1e-6)\n",
    "    scaler = GradScaler(enabled=True)\n",
    "\n",
    "    best_iou = 0.0\n",
    "    if resume_from and resume_from.exists():\n",
    "        try:\n",
    "            st = torch.load(resume_from, map_location=\"cpu\", weights_only=False)\n",
    "            if isinstance(st, dict):\n",
    "                best_iou = st.get(\"best_iou\", 0.0)\n",
    "                print(f\"  Resuming with best_iou = {best_iou:.4f}\")\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    try:\n",
    "        for i, sub_name in enumerate(sub_maps, 1):\n",
    "            print(f\"\\n  [{i}/{len(sub_maps)}] Training {sub_name} ‚Ä¶\")\n",
    "            model_w, optimizer, scheduler, scaler, best_iou = train_submap(\n",
    "                sub_name, model_w, optimizer, scheduler, scaler, best_iou\n",
    "            )\n",
    "    except (Exception, KeyboardInterrupt) as e:\n",
    "        print(f\"\\n  ‚ö†Ô∏è EMERGENCY SAVE: {e}\")\n",
    "        torch.save(model_w.state_dict(), CKPT_DIR / \"MAP_crash_backup.pt\")\n",
    "        raise e\n",
    "\n",
    "    print(f\"\\n  ‚úÖ {parent_map} complete ‚Äî best IoU: {best_iou:.4f}\")\n",
    "    return BEST_CKPT if BEST_CKPT.exists() else LATEST_CKPT\n",
    "\n",
    "print(f\"‚úÖ Logic Ready & Modules Imported | GPU: {gpu_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell3-md",
   "metadata": {},
   "source": [
    "---\n",
    "## Cell 3 ‚Äî Execute Training\n",
    "Trains each sub-map individually. One global `MAP_best.pt` / `MAP_latest.pt`. Asks permission before next parent map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discover sub-map folders and group by parent map\n",
    "sub_folders = sorted([\n",
    "    d.name for d in DATA_DIR.iterdir()\n",
    "    if d.is_dir() and d.name.startswith(\"MAP\") and \".\" in d.name\n",
    "])\n",
    "\n",
    "parent_maps = []\n",
    "seen = set()\n",
    "for name in sub_folders:\n",
    "    parent = name.split(\".\")[0]\n",
    "    if parent not in seen:\n",
    "        seen.add(parent)\n",
    "        parent_maps.append(parent)\n",
    "parent_maps.sort()\n",
    "\n",
    "sub_counts = {p: sum(1 for n in sub_folders if n.startswith(p + \".\")) for p in parent_maps}\n",
    "print(f\"üöÄ Found {len(parent_maps)} parent maps: {[f'{p} ({sub_counts[p]} sub-maps)' for p in parent_maps]}\")\n",
    "print(f\"Checkpoints: {BEST_CKPT} / {LATEST_CKPT}\\n\")\n",
    "\n",
    "prev_ckpt = BEST_CKPT if BEST_CKPT.exists() else None\n",
    "\n",
    "for idx, p_name in enumerate(parent_maps):\n",
    "    # Ask permission before each parent map (except the first)\n",
    "    if idx > 0:\n",
    "        answer = input(f\"\\nüîî Continue to {p_name} ({sub_counts[p_name]} sub-maps)? [yes/no]: \").strip().lower()\n",
    "        if answer not in (\"yes\", \"y\"):\n",
    "            print(f\"‚õî Stopped before {p_name}. Checkpoints saved.\")\n",
    "            break\n",
    "\n",
    "    print(f\"\\n‚è≥ Training {p_name} ({sub_counts[p_name]} sub-maps individually)...\")\n",
    "    ckpt = train_parent_map(p_name, resume_from=prev_ckpt)\n",
    "    if ckpt and Path(ckpt).exists():\n",
    "        prev_ckpt = ckpt\n",
    "    else:\n",
    "        print(f\"‚ùå {p_name} failed\")\n",
    "\n",
    "print(\"\\n*** DGX TRAINING COMPLETE ***\")\n",
    "print(f\"Best checkpoint : {BEST_CKPT}  (exists={BEST_CKPT.exists()})\")\n",
    "print(f\"Latest checkpoint: {LATEST_CKPT}  (exists={LATEST_CKPT.exists()})\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.14.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.14.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
