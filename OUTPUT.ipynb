{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro",
   "metadata": {},
   "source": [
    "# SVAMITVA Feature Extraction — Universal Training Pipeline\n",
    "\n",
    "**Objective:** Train a unified multi-task segmentation model capable of extracting 10 shapefile classes from Drone Imagery. \n",
    "\n",
    "This notebook supports training on a DGX A100 Server (CUDA) and local Apple Silicon (MPS/CPU) environments automatically.\n",
    "\n",
    "## Environment Workflow\n",
    "1. Put data in a folder structured like `DATA/MAP1/*.tif`.\n",
    "2. Execute the Setup (Cell 1).\n",
    "3. Execute Training (Cell 2).\n",
    "4. Wait for Universal `MAP5_best.pt` to be stored in the `./checkpoints/` directory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell1-md",
   "metadata": {},
   "source": [
    "---\n",
    "## CELL 1 — Setup & Environment Configuration (Run Once)\n",
    "This cell dynamically checks variables, imports required codebase files (`feature_extractor.py`, etc.), and allocates resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cell1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-24T16:43:56.750033Z",
     "iopub.status.busy": "2026-02-24T16:43:56.749808Z",
     "iopub.status.idle": "2026-02-24T16:43:57.159090Z",
     "shell.execute_reply": "2026-02-24T16:43:57.158690Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml  # type: ignore[import]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment  : Local PC\n",
      "DATA dir     : /Users/aaronr/Downloads/geoii-main/DATA  (exists=True)\n",
      "Device       : mps\n",
      "\n",
      "\n",
      "Imports and Configuration Complete ✓\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "# Ensure PyTorch handles high memory loads on DGX natively\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.amp import GradScaler, autocast  # Handles PyTorch 2.4/2.5+ safely\n",
    "\n",
    "# ── Workspace Directory Checking ──────────────────────────────────────────\n",
    "NOTEBOOK_DIR = Path.cwd()\n",
    "if str(NOTEBOOK_DIR) not in sys.path:\n",
    "    sys.path.insert(0, str(NOTEBOOK_DIR))\n",
    "\n",
    "DGX_DATA_DIR = Path(\"/jupyter/sods.user04/DATA\")\n",
    "LOCAL_DATA_DIR = NOTEBOOK_DIR / \"DATA\"\n",
    "FALLBACK_LOCAL = NOTEBOOK_DIR.parent / \"DATA\"\n",
    "\n",
    "if DGX_DATA_DIR.exists():\n",
    "    DATA_DIR = DGX_DATA_DIR\n",
    "    ENV_TYPE = \"DGX GPU Cluster\"\n",
    "elif LOCAL_DATA_DIR.exists():\n",
    "    DATA_DIR = LOCAL_DATA_DIR\n",
    "    ENV_TYPE = \"Local PC\"\n",
    "elif FALLBACK_LOCAL.exists():\n",
    "    DATA_DIR = FALLBACK_LOCAL\n",
    "    ENV_TYPE = \"Local PC (Parent Dir)\"\n",
    "else:\n",
    "    print(f\"[WARNING] No DATA folder found directly! Assuming DGX/Linux mount failure. Will artificially default to {DGX_DATA_DIR}, please create a /DATA directory containing MAP1, MAP2, etc.\")\n",
    "    DATA_DIR = LOCAL_DATA_DIR\n",
    "    ENV_TYPE = \"Missing / Artificial\"\n",
    "\n",
    "CKPT_DIR = NOTEBOOK_DIR / \"checkpoints\"\n",
    "CKPT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "(NOTEBOOK_DIR / \"logs\").mkdir(exist_ok=True)\n",
    "\n",
    "# ── Device Allocation (CUDA / MPS / CPU) ──────────────────────────────────\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    amp_device = \"cuda\"\n",
    "elif torch.backends.mps.is_available() and torch.backends.mps.is_built():\n",
    "    device = torch.device(\"mps\")\n",
    "    amp_device = \"cpu\" # AutoCast is mostly disabled/flaky for MPS, using CPU autocast for safety\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    amp_device = \"cpu\"\n",
    "\n",
    "print(f\"Environment  : {ENV_TYPE}\")\n",
    "print(f\"DATA dir     : {DATA_DIR}  (exists={DATA_DIR.exists()})\")\n",
    "print(f\"Device       : {device}\\n\")\n",
    "if device.type == \"cuda\":\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        g = torch.cuda.get_device_properties(i)\n",
    "        print(f\"  GPU {i}: {g.name}  ({g.total_memory/1e9:.1f} GB)\")\n",
    "\n",
    "# ── Training Configuration ────────────────────────────────────────────────\n",
    "CONFIG = dict(\n",
    "    backbone         = \"resnet50\",\n",
    "    pretrained       = True,   # Automatically fetch generic image weights locally\n",
    "    image_size       = 512,\n",
    "    batch_size       = 8 if device.type == \"cuda\" else 4,   # Reduce for local debugging\n",
    "    epochs_per_map   = 50,\n",
    "    learning_rate    = 2e-4,\n",
    "    weight_decay     = 1e-4,\n",
    "    num_workers      = 0,\n",
    "    mixed_precision  = device.type == \"cuda\",\n",
    "    gradient_clip    = 1.0,\n",
    "    \n",
    "    # Priority multi-task loss weightings\n",
    "    building_weight        = 1.0,\n",
    "    roof_weight            = 0.5,\n",
    "    road_weight            = 0.8,\n",
    "    waterbody_weight       = 0.8,\n",
    "    road_centerline_weight = 0.7,\n",
    "    waterbody_line_weight  = 0.7,\n",
    "    waterbody_point_weight = 0.9,\n",
    "    utility_line_weight    = 0.7,\n",
    "    utility_poly_weight    = 0.8,\n",
    "    bridge_weight          = 1.0,\n",
    "    railway_weight         = 0.9,\n",
    ")\n",
    "\n",
    "TARGET_KEYS = [\n",
    "    \"building_mask\", \"road_mask\", \"road_centerline_mask\",\n",
    "    \"waterbody_mask\", \"waterbody_line_mask\", \"waterbody_point_mask\",\n",
    "    \"utility_line_mask\", \"utility_poly_mask\",\n",
    "    \"bridge_mask\", \"railway_mask\", \"roof_type_mask\",\n",
    "]\n",
    "\n",
    "print(\"\\nImports and Configuration Complete ✓\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell2-md",
   "metadata": {},
   "source": [
    "---\n",
    "## CELL 2 — Training Engine Core\n",
    "Initializes building blocks from the native `.py` codebase: dataset loading, architecture, logic scaling, focal loss algorithms, backwards passes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cell2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-24T16:43:57.160428Z",
     "iopub.status.busy": "2026-02-24T16:43:57.160327Z",
     "iopub.status.idle": "2026-02-24T16:43:58.520412Z",
     "shell.execute_reply": "2026-02-24T16:43:58.519450Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Core Active ✓\n"
     ]
    }
   ],
   "source": [
    "from models.feature_extractor import FeatureExtractorModel\n",
    "from models.losses import MultiTaskLoss\n",
    "from training.metrics import MetricTracker\n",
    "from data.dataset import SvamitvaDataset\n",
    "from data.augmentation import get_train_transforms\n",
    "\n",
    "def move_targets(batch):\n",
    "    return {k: batch[k].to(device) for k in TARGET_KEYS if k in batch}\n",
    "\n",
    "def build_model(load_from: Path = None):\n",
    "    m = FeatureExtractorModel(\n",
    "        backbone=CONFIG[\"backbone\"],\n",
    "        pretrained=CONFIG[\"pretrained\"],\n",
    "        num_roof_classes=5,\n",
    "    )\n",
    "    if load_from and load_from.exists():\n",
    "        state = torch.load(load_from, map_location=\"cpu\")\n",
    "        m.load_state_dict(state[\"model\"], strict=False)\n",
    "        print(f\"Loaded weights from checkpoint: {load_from.name}\")\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        m = nn.DataParallel(m)\n",
    "    return m.to(device)\n",
    "\n",
    "\n",
    "def train_map(map_name: str, resume_from: Path = None):\n",
    "    map_dir  = DATA_DIR / map_name\n",
    "    best_out = CKPT_DIR / f\"{map_name}_best.pt\"\n",
    "    last_out = CKPT_DIR / f\"{map_name}_latest.pt\"\n",
    "\n",
    "    if not map_dir.exists():\n",
    "        print(f\"[SKIPPING/ERROR] Folder NOT FOUND: {map_dir}\")\n",
    "        return best_out if best_out.exists() else None\n",
    "\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"  Training Engine Activating for Region : {map_name}\")\n",
    "    print(f\"  Loading prior state weights           : {resume_from.name if resume_from and resume_from.exists() else 'RANDOM / SCRATCH'}\")\n",
    "    print(f\"{'='*70}\")\n",
    "\n",
    "    # Model, Engine Setup\n",
    "    model_w   = build_model(load_from=resume_from)\n",
    "    inner     = model_w.module if isinstance(model_w, nn.DataParallel) else model_w\n",
    "\n",
    "    # Dataset Setup\n",
    "    try:\n",
    "        ds = SvamitvaDataset(\n",
    "            root_dir   = DATA_DIR,\n",
    "            image_size = CONFIG[\"image_size\"],\n",
    "            transform  = get_train_transforms(CONFIG[\"image_size\"]),\n",
    "            mode       = \"train\",\n",
    "        )\n",
    "        ds.samples = [s for s in ds.samples if s[\"map_name\"] == map_name]\n",
    "        print(f\"  Generated dynamically cached tiles    : {len(ds)}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to load dataset for {map_name}: {e}\")\n",
    "        return None\n",
    "\n",
    "    loader = DataLoader(ds, batch_size=CONFIG[\"batch_size\"], shuffle=True, num_workers=CONFIG[\"num_workers\"], pin_memory=(device.type == \"cuda\"))\n",
    "\n",
    "    # Loss Setup (Includes BinaryFocalLoss)\n",
    "    loss_fn = MultiTaskLoss(**{k: v for k, v in CONFIG.items() if k.endswith(\"_weight\")}).to(device)\n",
    "    optimizer = torch.optim.AdamW(model_w.parameters(), lr=CONFIG[\"learning_rate\"], weight_decay=CONFIG[\"weight_decay\"])\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=CONFIG[\"epochs_per_map\"], eta_min=1e-6)\n",
    "    \n",
    "    # Mixed precision tracking (only cuda natively fully handles this reliably in PyTorch amp currently)\n",
    "    use_amp = device.type == \"cuda\"\n",
    "    scaler = GradScaler(enabled=use_amp, device='cuda' if use_amp else None)\n",
    "\n",
    "    # Loop\n",
    "    best_iou  = 0.0\n",
    "    for epoch in range(1, CONFIG[\"epochs_per_map\"] + 1):\n",
    "        model_w.train()\n",
    "        tracker  = MetricTracker()\n",
    "        run_loss = 0.0\n",
    "        n_steps  = 0\n",
    "        t0       = time.time()\n",
    "\n",
    "        for batch in loader:\n",
    "            images  = batch[\"image\"].to(device)\n",
    "            targets = move_targets(batch)\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            \n",
    "            # Forward Pass\n",
    "            with autocast(device_type=amp_device, enabled=use_amp):\n",
    "                preds         = model_w(images)\n",
    "                total_loss, loss_dict = loss_fn(preds, targets)\n",
    "            \n",
    "            # NaN Guard & Backward Pass\n",
    "            if not torch.isfinite(total_loss):\n",
    "                print(f\"      [NaN SKIP] skipping bad gradients in step...\")\n",
    "                continue \n",
    "\n",
    "            if use_amp:\n",
    "                scaler.scale(total_loss).backward()\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "            else:\n",
    "                total_loss.backward()\n",
    "                if CONFIG[\"gradient_clip\"] > 0:\n",
    "                    nn.utils.clip_grad_norm_(model_w.parameters(), CONFIG[\"gradient_clip\"])\n",
    "                optimizer.step()\n",
    "\n",
    "            run_loss += total_loss.item()\n",
    "            tracker.update(preds, targets)\n",
    "            n_steps += 1\n",
    "\n",
    "        scheduler.step()\n",
    "        m        = tracker.compute()\n",
    "        avg_loss = run_loss / max(n_steps, 1)\n",
    "        avg_iou  = m.get(\"avg_iou\", 0.0)\n",
    "\n",
    "        print((f\"  Epoch {epoch:2d}/{CONFIG['epochs_per_map']} | \"\n",
    "               f\"loss: {avg_loss:.4f} | iou: {avg_iou:.4f} | \"\n",
    "               f\"time: {time.time()-t0:.0f}s\"))\n",
    "\n",
    "        # Checkpointing\n",
    "        ckpt = {\n",
    "            \"model\"    : inner.state_dict(),\n",
    "            \"epoch\"    : epoch,\n",
    "            \"map_name\" : map_name,\n",
    "            \"best_iou\" : best_iou,\n",
    "            \"metrics\"  : m,\n",
    "        }\n",
    "        torch.save(ckpt, last_out)\n",
    "        if avg_iou > best_iou:\n",
    "            best_iou = avg_iou\n",
    "            ckpt[\"best_iou\"] = best_iou\n",
    "            torch.save(ckpt, best_out)\n",
    "            print(f\"    → New Best Checkpoint saved! IoU = {best_iou:.4f}\")\n",
    "\n",
    "    print(f\"\\n  [MAP COMPLETE] {map_name} finished.  Best IoU={best_iou:.4f}\")\n",
    "    return best_out\n",
    "\n",
    "def analyse_checkpoint(ckpt_path: Path):\n",
    "    if not ckpt_path.exists():\n",
    "        print(f\"Checkpoint missing: {ckpt_path}\")\n",
    "        return\n",
    "    st = torch.load(ckpt_path, map_location=\"cpu\")\n",
    "    m  = st.get(\"metrics\", {})\n",
    "    print(f\"\\n{'─'*60}\")\n",
    "    print(f\"  Checkpoint : {ckpt_path.name}\")\n",
    "    print(f\"  MAP trained: {st.get('map_name','?')} | Epoch {st.get('epoch','?')} | Best IoU {st.get('best_iou',0):.4f}\")\n",
    "    print(f\"  Per-task IoU:\")\n",
    "    for k, v in m.items():\n",
    "        if k.endswith(\"_iou\") and k != \"avg_iou\":\n",
    "            bar = \"█\" * int(v * 20)\n",
    "            print(f\"    {k:30s} {v:.4f}  {bar}\")\n",
    "    print(f\"{'─'*60}\\n\")\n",
    "print(\"Training Core Active ✓\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell3-md",
   "metadata": {},
   "source": [
    "---\n",
    "## CELL 3 — Executive Training Suite \n",
    "Run this block sequentially. It handles progressive multi-map knowledge assimilation ("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cell3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-24T16:43:58.523388Z",
     "iopub.status.busy": "2026-02-24T16:43:58.523029Z",
     "iopub.status.idle": "2026-02-24T16:43:58.527811Z",
     "shell.execute_reply": "2026-02-24T16:43:58.527079Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SKIPPING/ERROR] Folder NOT FOUND: /Users/aaronr/Downloads/geoii-main/DATA/MAP1\n",
      "[SKIPPING/ERROR] Folder NOT FOUND: /Users/aaronr/Downloads/geoii-main/DATA/MAP2\n",
      "[SKIPPING/ERROR] Folder NOT FOUND: /Users/aaronr/Downloads/geoii-main/DATA/MAP3\n",
      "[SKIPPING/ERROR] Folder NOT FOUND: /Users/aaronr/Downloads/geoii-main/DATA/MAP4\n",
      "[SKIPPING/ERROR] Folder NOT FOUND: /Users/aaronr/Downloads/geoii-main/DATA/MAP5\n",
      "\n",
      "*** SVAMITVA UNIVERSAL PIPELINE EXHAUSTED ***\n",
      "Final Model Weights successfully saved in ./checkpoints/\n"
     ]
    }
   ],
   "source": [
    "# Execute progressively. It handles missing maps gracefully, carrying over checkpoints across regions \n",
    "cpt1 = train_map(\"MAP1\", resume_from=None)\n",
    "if cpt1: analyse_checkpoint(cpt1)\n",
    "\n",
    "cpt2 = train_map(\"MAP2\", resume_from=cpt1)\n",
    "if cpt2: analyse_checkpoint(cpt2)\n",
    "\n",
    "cpt3 = train_map(\"MAP3\", resume_from=cpt2)\n",
    "if cpt3: analyse_checkpoint(cpt3)\n",
    "\n",
    "cpt4 = train_map(\"MAP4\", resume_from=cpt3)\n",
    "if cpt4: analyse_checkpoint(cpt4)\n",
    "\n",
    "cpt5 = train_map(\"MAP5\", resume_from=cpt4)\n",
    "if cpt5: analyse_checkpoint(cpt5)\n",
    "\n",
    "print(\"\\n*** SVAMITVA UNIVERSAL PIPELINE EXHAUSTED ***\")\n",
    "print(\"Final Model Weights successfully saved in ./checkpoints/\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
