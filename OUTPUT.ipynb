{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "intro",
            "metadata": {},
            "source": [
                "# SVAMITVA Feature Extraction — Universal Training Pipeline\n",
                "\n",
                "**Objective:** Train a unified multi-task segmentation model to extract 10 shapefile classes from Drone Imagery.\n",
                "\n",
                "Automatically detects environment: DGX A100 (CUDA) or Apple Silicon (MPS/CPU).\n",
                "\n",
                "## Workflow\n",
                "1. Structure data as `DATA/MAP1/*.tif` + `*.shp` files\n",
                "2. Run **Cell 1** (Setup — run once)\n",
                "3. Run **Cell 2** (Training Engine — run once)\n",
                "4. Run **Cell 3** (Execute Training — run to completion)\n",
                "5. Best checkpoint saved as `./checkpoints/MAP5_best.pt`"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "cell1-md",
            "metadata": {},
            "source": [
                "---\n",
                "## Cell 1 — Setup & Environment Configuration\n",
                "Detects hardware, sets DATA path, creates config."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "cell1",
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import sys\n",
                "import time\n",
                "from pathlib import Path\n",
                "\n",
                "# Must be set before any CUDA context is created\n",
                "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
                "\n",
                "import torch\n",
                "import torch.nn as nn\n",
                "from torch.utils.data import DataLoader\n",
                "from torch.amp import GradScaler, autocast\n",
                "\n",
                "# ── Workspace path setup ────────────────────────────────────────────────────\n",
                "NOTEBOOK_DIR = Path.cwd()\n",
                "if str(NOTEBOOK_DIR) not in sys.path:\n",
                "    sys.path.insert(0, str(NOTEBOOK_DIR))\n",
                "\n",
                "# Auto-detect DATA directory\n",
                "DGX_DATA_DIR   = Path(\"/jupyter/sods.user04/DATA\")\n",
                "LOCAL_DATA_DIR = NOTEBOOK_DIR / \"DATA\"\n",
                "FALLBACK_LOCAL = NOTEBOOK_DIR.parent / \"DATA\"\n",
                "\n",
                "if DGX_DATA_DIR.exists():\n",
                "    DATA_DIR, ENV_TYPE = DGX_DATA_DIR, \"DGX GPU Cluster\"\n",
                "elif LOCAL_DATA_DIR.exists():\n",
                "    DATA_DIR, ENV_TYPE = LOCAL_DATA_DIR, \"Local PC\"\n",
                "elif FALLBACK_LOCAL.exists():\n",
                "    DATA_DIR, ENV_TYPE = FALLBACK_LOCAL, \"Local PC (Parent Dir)\"\n",
                "else:\n",
                "    print(\"[WARNING] No DATA folder found. Defaulting to LOCAL_DATA_DIR.\")\n",
                "    DATA_DIR, ENV_TYPE = LOCAL_DATA_DIR, \"Missing / Artificial\"\n",
                "\n",
                "CKPT_DIR = NOTEBOOK_DIR / \"checkpoints\"\n",
                "CKPT_DIR.mkdir(parents=True, exist_ok=True)\n",
                "(NOTEBOOK_DIR / \"logs\").mkdir(exist_ok=True)\n",
                "\n",
                "# ── Device detection ────────────────────────────────────────────────────────\n",
                "if torch.cuda.is_available():\n",
                "    device, amp_device = torch.device(\"cuda\"), \"cuda\"\n",
                "elif torch.backends.mps.is_available() and torch.backends.mps.is_built():\n",
                "    device, amp_device = torch.device(\"mps\"), \"cpu\"  # MPS autocast is flaky\n",
                "else:\n",
                "    device, amp_device = torch.device(\"cpu\"), \"cpu\"\n",
                "\n",
                "print(f\"Environment : {ENV_TYPE}\")\n",
                "print(f\"DATA dir    : {DATA_DIR}  (exists={DATA_DIR.exists()})\")\n",
                "print(f\"Device      : {device}\")\n",
                "if device.type == \"cuda\":\n",
                "    for i in range(torch.cuda.device_count()):\n",
                "        g = torch.cuda.get_device_properties(i)\n",
                "        print(f\"  GPU {i}: {g.name}  ({g.total_memory/1e9:.1f} GB)\")\n",
                "\n",
                "# ── Training configuration ───────────────────────────────────────────────────\n",
                "CONFIG = dict(\n",
                "    backbone              = \"resnet50\",\n",
                "    pretrained            = True,\n",
                "    image_size            = 512,\n",
                "    batch_size            = 8 if device.type == \"cuda\" else 4,\n",
                "    epochs_per_map        = 50,\n",
                "    learning_rate         = 2e-4,\n",
                "    weight_decay          = 1e-4,\n",
                "    num_workers           = 0,\n",
                "    mixed_precision       = device.type == \"cuda\",\n",
                "    gradient_clip         = 1.0,\n",
                "    building_weight       = 1.0,\n",
                "    roof_weight           = 0.5,\n",
                "    road_weight           = 0.8,\n",
                "    waterbody_weight      = 0.8,\n",
                "    road_centerline_weight= 0.7,\n",
                "    waterbody_line_weight = 0.7,\n",
                "    waterbody_point_weight= 0.9,\n",
                "    utility_line_weight   = 0.7,\n",
                "    utility_poly_weight   = 0.8,\n",
                "    bridge_weight         = 1.0,\n",
                "    railway_weight        = 0.9,\n",
                ")\n",
                "\n",
                "TARGET_KEYS = [\n",
                "    \"building_mask\", \"road_mask\", \"road_centerline_mask\",\n",
                "    \"waterbody_mask\", \"waterbody_line_mask\", \"waterbody_point_mask\",\n",
                "    \"utility_line_mask\", \"utility_poly_mask\",\n",
                "    \"bridge_mask\", \"railway_mask\", \"roof_type_mask\",\n",
                "]\n",
                "\n",
                "print(\"\\nSetup complete ✓\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "cell2-md",
            "metadata": {},
            "source": [
                "---\n",
                "## Cell 2 — Training Engine Core\n",
                "Loads model, dataset, loss, and defines `train_map` and `analyse_checkpoint`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "cell2",
            "metadata": {},
            "outputs": [],
            "source": [
                "from models.feature_extractor import FeatureExtractor\n",
                "from models.losses import MultiTaskLoss\n",
                "from training.metrics import MetricTracker\n",
                "from data.dataset import SvamitvaDataset\n",
                "from data.augmentation import get_train_transforms\n",
                "\n",
                "def move_targets(batch):\n",
                "    return {k: batch[k].to(device) for k in TARGET_KEYS if k in batch}\n",
                "\n",
                "def build_model(load_from: Path = None):\n",
                "    m = FeatureExtractor(\n",
                "        backbone=CONFIG[\"backbone\"],\n",
                "        pretrained=CONFIG[\"pretrained\"],\n",
                "        num_roof_classes=5,\n",
                "    )\n",
                "    if load_from and load_from.exists():\n",
                "        state = torch.load(load_from, map_location=\"cpu\", weights_only=False)\n",
                "        # Support both raw state_dict and wrapped checkpoint\n",
                "        weights = state.get(\"model\") or state.get(\"model_state_dict\") or state\n",
                "        m.load_state_dict(weights, strict=False)\n",
                "        print(f\"Loaded weights: {load_from.name}\")\n",
                "    if torch.cuda.device_count() > 1:\n",
                "        m = nn.DataParallel(m)\n",
                "    return m.to(device)\n",
                "\n",
                "\n",
                "def train_map(map_name: str, resume_from: Path = None):\n",
                "    map_dir  = DATA_DIR / map_name\n",
                "    best_out = CKPT_DIR / f\"{map_name}_best.pt\"\n",
                "    last_out = CKPT_DIR / f\"{map_name}_latest.pt\"\n",
                "\n",
                "    if not map_dir.exists():\n",
                "        print(f\"[SKIP] Folder not found: {map_dir}\")\n",
                "        return best_out if best_out.exists() else None\n",
                "\n",
                "    print(f\"\\n{'='*70}\")\n",
                "    print(f\"  Region     : {map_name}\")\n",
                "    print(f\"  Checkpoint : {resume_from.name if resume_from and resume_from.exists() else 'RANDOM / SCRATCH'}\")\n",
                "    print(f\"{'='*70}\")\n",
                "\n",
                "    model_w = build_model(load_from=resume_from)\n",
                "    inner   = model_w.module if isinstance(model_w, nn.DataParallel) else model_w\n",
                "\n",
                "    # Dataset\n",
                "    try:\n",
                "        ds = SvamitvaDataset(\n",
                "            root_dir=DATA_DIR,\n",
                "            image_size=CONFIG[\"image_size\"],\n",
                "            transform=get_train_transforms(CONFIG[\"image_size\"]),\n",
                "            mode=\"train\",\n",
                "        )\n",
                "        ds.samples = [s for s in ds.samples if s[\"map_name\"] == map_name]\n",
                "        print(f\"  Tiles: {len(ds)}\")\n",
                "    except Exception as e:\n",
                "        print(f\"Dataset load failed for {map_name}: {e}\")\n",
                "        return None\n",
                "\n",
                "    loader = DataLoader(\n",
                "        ds,\n",
                "        batch_size=CONFIG[\"batch_size\"],\n",
                "        shuffle=True,\n",
                "        num_workers=CONFIG[\"num_workers\"],\n",
                "        pin_memory=(device.type == \"cuda\"),\n",
                "    )\n",
                "\n",
                "    loss_fn   = MultiTaskLoss(**{k: v for k, v in CONFIG.items() if k.endswith(\"_weight\")}).to(device)\n",
                "    optimizer = torch.optim.AdamW(model_w.parameters(), lr=CONFIG[\"learning_rate\"], weight_decay=CONFIG[\"weight_decay\"])\n",
                "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=CONFIG[\"epochs_per_map\"], eta_min=1e-6)\n",
                "    use_amp   = device.type == \"cuda\"\n",
                "    scaler    = GradScaler(enabled=use_amp, device=\"cuda\" if use_amp else None)\n",
                "\n",
                "    best_iou = 0.0\n",
                "    for epoch in range(1, CONFIG[\"epochs_per_map\"] + 1):\n",
                "        model_w.train()\n",
                "        tracker  = MetricTracker()\n",
                "        run_loss = 0.0\n",
                "        n_steps  = 0\n",
                "        t0       = time.time()\n",
                "\n",
                "        for batch in loader:\n",
                "            images  = batch[\"image\"].to(device)\n",
                "            targets = move_targets(batch)\n",
                "            optimizer.zero_grad(set_to_none=True)\n",
                "\n",
                "            with autocast(device_type=amp_device, enabled=use_amp):\n",
                "                preds               = model_w(images)\n",
                "                total_loss, loss_d  = loss_fn(preds, targets)\n",
                "\n",
                "            if not torch.isfinite(total_loss):\n",
                "                print(f\"  [NaN SKIP] epoch {epoch} step {n_steps}\")\n",
                "                continue\n",
                "\n",
                "            if use_amp:\n",
                "                scaler.scale(total_loss).backward()\n",
                "                if CONFIG[\"gradient_clip\"] > 0:\n",
                "                    scaler.unscale_(optimizer)\n",
                "                    nn.utils.clip_grad_norm_(model_w.parameters(), CONFIG[\"gradient_clip\"])\n",
                "                scaler.step(optimizer)\n",
                "                scaler.update()\n",
                "            else:\n",
                "                total_loss.backward()\n",
                "                if CONFIG[\"gradient_clip\"] > 0:\n",
                "                    nn.utils.clip_grad_norm_(model_w.parameters(), CONFIG[\"gradient_clip\"])\n",
                "                optimizer.step()\n",
                "\n",
                "            run_loss += total_loss.item()\n",
                "            tracker.update(preds, targets)\n",
                "            n_steps += 1\n",
                "\n",
                "        scheduler.step()\n",
                "        m        = tracker.compute()\n",
                "        avg_loss = run_loss / max(n_steps, 1)\n",
                "        avg_iou  = m.get(\"avg_iou\", 0.0)\n",
                "\n",
                "        print(f\"  Epoch {epoch:2d}/{CONFIG['epochs_per_map']} | loss: {avg_loss:.4f} | iou: {avg_iou:.4f} | {time.time()-t0:.0f}s\")\n",
                "\n",
                "        ckpt = {\"model\": inner.state_dict(), \"epoch\": epoch, \"map_name\": map_name, \"best_iou\": best_iou, \"metrics\": m}\n",
                "        torch.save(ckpt, last_out)\n",
                "        if avg_iou > best_iou:\n",
                "            best_iou = avg_iou\n",
                "            ckpt[\"best_iou\"] = best_iou\n",
                "            torch.save(ckpt, best_out)\n",
                "            print(f\"    → New best! IoU = {best_iou:.4f}\")\n",
                "\n",
                "    print(f\"\\n  [DONE] {map_name}  Best IoU={best_iou:.4f}\")\n",
                "    return best_out\n",
                "\n",
                "\n",
                "def analyse_checkpoint(ckpt_path: Path):\n",
                "    if not ckpt_path or not ckpt_path.exists():\n",
                "        print(f\"Checkpoint missing: {ckpt_path}\")\n",
                "        return\n",
                "    st = torch.load(ckpt_path, map_location=\"cpu\", weights_only=False)\n",
                "    m  = st.get(\"metrics\", {})\n",
                "    print(f\"\\n{'─'*60}\")\n",
                "    print(f\"  Checkpoint : {ckpt_path.name}\")\n",
                "    print(f\"  MAP: {st.get('map_name','?')} | Epoch {st.get('epoch','?')} | Best IoU {st.get('best_iou',0):.4f}\")\n",
                "    for k, v in m.items():\n",
                "        if k.endswith(\"_iou\") and k != \"avg_iou\":\n",
                "            bar = \"█\" * int(v * 20)\n",
                "            print(f\"  {k:30s} {v:.4f}  {bar}\")\n",
                "    print(f\"{'─'*60}\\n\")\n",
                "\n",
                "print(\"Training engine ready ✓\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "cell3-md",
            "metadata": {},
            "source": [
                "---\n",
                "## Cell 3 — Execute Training\n",
                "Progressive multi-map training. Each MAP inherits weights from the previous one."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "cell3",
            "metadata": {},
            "outputs": [],
            "source": [
                "cpt1 = train_map(\"MAP1\", resume_from=None)\n",
                "if cpt1: analyse_checkpoint(cpt1)\n",
                "\n",
                "cpt2 = train_map(\"MAP2\", resume_from=cpt1)\n",
                "if cpt2: analyse_checkpoint(cpt2)\n",
                "\n",
                "cpt3 = train_map(\"MAP3\", resume_from=cpt2)\n",
                "if cpt3: analyse_checkpoint(cpt3)\n",
                "\n",
                "cpt4 = train_map(\"MAP4\", resume_from=cpt3)\n",
                "if cpt4: analyse_checkpoint(cpt4)\n",
                "\n",
                "cpt5 = train_map(\"MAP5\", resume_from=cpt4)\n",
                "if cpt5: analyse_checkpoint(cpt5)\n",
                "\n",
                "print(\"\\n*** SVAMITVA UNIVERSAL PIPELINE COMPLETE ***\")\n",
                "print(\"Final weights saved in ./checkpoints/\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
